{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from view_sampler import ViewSampler, CameraConfig\n",
    "from manipulated_object import ObjectPosition\n",
    "import loss_funcs\n",
    "from evaluate import eval_funcs\n",
    "from algs import *\n",
    "\n",
    "from utils.orient import OrientUtils\n",
    "from evaluate.evaluator import Evaluator\n",
    "from utils.visualize import SearchPlotter\n",
    "from utils.image import ImageUtils\n",
    "\n",
    "import mealpy\n",
    "import cv2 as cv\n",
    "\n",
    "plotter = SearchPlotter(update_freq=100)\n",
    "\n",
    "# Create a camera configuration\n",
    "cam_config = CameraConfig(location=(0, 0, 0.1), rotation=(np.pi / 2, 0, 0), fov=60)\n",
    "world_viewer = ViewSampler(\"data/mug/world.xml\", cam_config, simulation_time=5)\n",
    "sim_viewer = ViewSampler(\"data/mug/world_sim.xml\", cam_config)\n",
    "\n",
    "loss_func = loss_funcs.IOU()\n",
    "\n",
    "alg = UniformSampling(sim_viewer, loss_func=loss_func)\n",
    "alg_config = UniformSampling.Config(time_limit=200, min_samples=350)\n",
    "\n",
    "eval_func=eval_funcs.XorDiff(0.1)\n",
    "evaluator = Evaluator(world_viewer, eval_func=eval_func)\n",
    "\n",
    "init_location = (0, 1.3, 0.3)\n",
    "random_orientations = OrientUtils.generate_random(80)\n",
    "eval_positions = [ObjectPosition(orient, init_location) for orient in random_orientations]\n",
    "\n",
    "for ref_pos in eval_positions:\n",
    "    orig_img = world_viewer.get_view_cropped(ref_pos)\n",
    "    pred_pos, loss = alg.solve(orig_img, ref_pos.location, alg_config)\n",
    "    pred_img = world_viewer.get_view_cropped(pred_pos)\n",
    "\n",
    "    cv.imshow(\"Original\", orig_img)\n",
    "    cv.waitKey(0)\n",
    "    cv.imshow(\"Predicted\", pred_img)\n",
    "    cv.waitKey(0)\n",
    "\n",
    "    orig_depth = world_viewer.get_view_cropped(ref_pos, depth=True)\n",
    "    pred_depth = world_viewer.get_view_cropped(pred_pos, depth=True)\n",
    "\n",
    "    eval_loss = eval_func(orig_depth, pred_depth)\n",
    "    print(eval_loss)\n",
    "\n",
    "for alg, config in [(alg, alg_config)]:\n",
    "    eval_losses = evaluator.evaluate(alg, config, eval_positions)\n",
    "    print(f\"{type(alg).__name__}: {eval_losses}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from view_sampler import ViewSampler, CameraConfig\n",
    "from manipulated_object import ObjectPosition\n",
    "import loss_funcs\n",
    "from evaluate import eval_funcs\n",
    "from algs import *\n",
    "\n",
    "from utils.orient import OrientUtils\n",
    "from evaluate.evaluator import Evaluator\n",
    "# from utils.visualize import SearchPlotter\n",
    "from utils.image import ImageUtils\n",
    "\n",
    "import mealpy\n",
    "import cv2 as cv\n",
    "\n",
    "# plotter = SearchPlotter(update_freq=100, alpha=[0.985])\n",
    "\n",
    "# Create a camera configuration\n",
    "cam_config = CameraConfig(location=(0, 0, 0.3), rotation=(np.pi / 2, 0, 0), fov=60)\n",
    "world_viewer = ViewSampler(\"data/hammer/world.xml\", cam_config, simulation_time=5)\n",
    "sim_viewer = ViewSampler(\"data/hammer/world_sim.xml\", cam_config)\n",
    "\n",
    "loss_func = loss_funcs.IOU()\n",
    "alg_config = MealAlgorithm.Config(time_limit=15, silent=True)\n",
    "\n",
    "eval_func=eval_funcs.XorDiff(0.1)\n",
    "\n",
    "evaluator = Evaluator(world_viewer, eval_func=eval_func)\n",
    "# evaluator.register_callback(lambda x: plotter.reset())\n",
    "\n",
    "init_location = (0, 1.3, 0.3)\n",
    "random_orientations = OrientUtils.generate_uniform(3)\n",
    "eval_positions = [ObjectPosition(orient, init_location) for orient in random_orientations]\n",
    "\n",
    "algorithms: list[MealAlgorithm] = [\n",
    "    MealAlgorithm(sim_viewer, loss_func, mealpy.physics_based.SA.OriginalSA(temp_init=10 * 2 * np.pi, step_size=0.1)),\n",
    "    MealAlgorithm(sim_viewer, loss_func, mealpy.physics_based.SA.SwarmSA(temp_init=10 * 2 * np.pi, step_size=np.pi/100)),\n",
    "    MealAlgorithm(sim_viewer, loss_func, mealpy.swarm_based.PSO.OriginalPSO()),\n",
    "    MealAlgorithm(sim_viewer, loss_func, mealpy.swarm_based.PSO.AIW_PSO()),\n",
    "]\n",
    "# meal_alg = mealpy.human_based.BRO.DevBRO()\n",
    "# meal_alg = mealpy.math_based.CEM.OriginalCEM()\n",
    "# meal_alg = mealpy.music_based.HS.DevHS(pop_size=10)\n",
    "# meal_alg = mealpy.swarm_based.PSO.OriginalPSO()\n",
    "# meal_alg = mealpy.physics_based.SA.OriginalSA(pop_size=10, temp_init=10 * 2 * np.pi, step_size=0.2)\n",
    "# meal_alg = mealpy.human_based.ICA.OriginalICA(empire_count=7, revolution_rate=0.4) # best!!\n",
    "# meal_alg = mealpy.bio_based.BBO.DevBBO() # potentially good!\n",
    "meal_alg = mealpy.bio_based.TSA.OriginalTSA() # potentially good!\n",
    "\n",
    "algorithms: list[MealAlgorithm] = [\n",
    "    MealAlgorithm(sim_viewer, loss_func, meal_alg),\n",
    "]\n",
    "\n",
    "# evaluator.enable_logging(\"Ealuations/UniformDet/Mug/IOU/\")\n",
    "for alg in algorithms:\n",
    "    # alg.register_callback(plotter.add_data)\n",
    "    eval_losses = evaluator.evaluate(alg, alg_config, eval_positions)\n",
    "    print(f\"{alg.get_name()}: {eval_losses}\")\n",
    "\n",
    "world_viewer.close()\n",
    "sim_viewer.close()\n",
    "# plotter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loss_funcs\n",
    "from algs import *\n",
    "\n",
    "import mealpy\n",
    "from multiprocessing import Process\n",
    "import evaluation_process as ev\n",
    "\n",
    "loss_func = loss_funcs.IOU()\n",
    "alg_config = MealAlgorithm.Config(time_limit=15, silent=True)\n",
    "root_path = \"Ealuations/OverNight/UniformDet/Hammer/IOU/\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for idx, (alg_name, meal_alg) in enumerate(mealpy.get_all_optimizers().items()):\n",
    "        if \"DevSARO\" not in alg_name:\n",
    "            continue\n",
    "        print(f\"===================== Epoch {idx} =====================\")\n",
    "        print(f\"Starting Evaluation of: {alg_name}\")\n",
    "        p = Process(target=ev.evaluate, args=(meal_alg,alg_config,loss_func,root_path))\n",
    "        p.start()\n",
    "        p.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.orient import OrientUtils\n",
    "len(OrientUtils.generate_uniform(9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from evaluate.eval_log import MealLog\n",
    "from mealpy.utils.history import History\n",
    "from utils.file import LogFiles\n",
    "import numpy as np\n",
    "\n",
    "path = \"grid_search/\"\n",
    "\n",
    "\n",
    "directories = LogFiles(path, scan_dirs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['list_global_best', 'list_current_best', 'list_epoch_time', 'list_global_best_fit', 'list_current_best_fit', 'list_population', 'list_diversity', 'list_exploitation', 'list_exploration', 'list_global_worst', 'list_current_worst', 'epoch', 'log_to', 'log_file', 'logger'])\n",
      "[2.470320265740156, 2.395192537456751, 2.5515127023682, 2.719743656925857, 2.4360504746437073, 2.6346693970263004]\n"
     ]
    }
   ],
   "source": [
    "a = MealLog.load(\"grid_search/airplane/OriginalICA_20240320-035635.pickle\")\n",
    "print(a.history_list[0].__dict__.keys())\n",
    "print((a.history_list[0].list_epoch_time))\n",
    "time = np.cumsum(a.history_list[0].list_epoch_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "times = []\n",
    "for hist in a.history_list:\n",
    "    # for t in hist.list_epoch_time:\n",
    "        # times.append(t)\n",
    "    print(len(hist.list_epoch_time))\n",
    "    # times.extend(hist.list_epoch_time)\n",
    "print(len(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 119 into shape (6,newaxis)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 119 into shape (6,newaxis)"
     ]
    }
   ],
   "source": [
    "\n",
    "np.array(times, ndmin=2).reshape(a.history_list[0].epoch, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alg</th>\n",
       "      <th>sample</th>\n",
       "      <th>epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>list_epoch_time</th>\n",
       "      <th>list_global_best_fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OriginalICA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038339</td>\n",
       "      <td>2.470320</td>\n",
       "      <td>0.456562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OriginalICA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038339</td>\n",
       "      <td>2.395193</td>\n",
       "      <td>0.306410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OriginalICA</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.038339</td>\n",
       "      <td>2.551513</td>\n",
       "      <td>0.165242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OriginalICA</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.038339</td>\n",
       "      <td>2.719744</td>\n",
       "      <td>0.122628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OriginalICA</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038339</td>\n",
       "      <td>2.436050</td>\n",
       "      <td>0.099407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>OriginalICA</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037917</td>\n",
       "      <td>2.605211</td>\n",
       "      <td>0.375155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>OriginalICA</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0.037917</td>\n",
       "      <td>2.410470</td>\n",
       "      <td>0.260627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>OriginalICA</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>0.037917</td>\n",
       "      <td>2.612240</td>\n",
       "      <td>0.207493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>OriginalICA</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037917</td>\n",
       "      <td>2.628524</td>\n",
       "      <td>0.168721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>OriginalICA</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>0.037917</td>\n",
       "      <td>2.888473</td>\n",
       "      <td>0.154973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             alg  sample  epoch  eval_loss  list_epoch_time  \\\n",
       "0    OriginalICA       0      0   0.038339         2.470320   \n",
       "1    OriginalICA       0      1   0.038339         2.395193   \n",
       "2    OriginalICA       0      2   0.038339         2.551513   \n",
       "3    OriginalICA       0      3   0.038339         2.719744   \n",
       "4    OriginalICA       0      4   0.038339         2.436050   \n",
       "..           ...     ...    ...        ...              ...   \n",
       "114  OriginalICA      19      1   0.037917         2.605211   \n",
       "115  OriginalICA      19      2   0.037917         2.410470   \n",
       "116  OriginalICA      19      3   0.037917         2.612240   \n",
       "117  OriginalICA      19      4   0.037917         2.628524   \n",
       "118  OriginalICA      19      5   0.037917         2.888473   \n",
       "\n",
       "     list_global_best_fit  \n",
       "0                0.456562  \n",
       "1                0.306410  \n",
       "2                0.165242  \n",
       "3                0.122628  \n",
       "4                0.099407  \n",
       "..                    ...  \n",
       "114              0.375155  \n",
       "115              0.260627  \n",
       "116              0.207493  \n",
       "117              0.168721  \n",
       "118              0.154973  \n",
       "\n",
       "[119 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.history_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in a.history_list[0].__dict__.items():\n",
    "    print(f\"key={key}; type={type(val)}; len={len(val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.history_list[0].list_global_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(a.history_list)):\n",
    "sns.lineplot(x=time, y=a.history_list[0].list_global_best_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = []\n",
    "stat_data = []\n",
    "for directory in directories:\n",
    "    files = LogFiles(directory, return_full_path=False)\n",
    "    for filename in files:\n",
    "        if \"OriginalHC\" not in filename:\n",
    "            continue\n",
    "        df = files.to_dataframe(add_params=True)\n",
    "        df = df.assign(object=directories.get_filename())\n",
    "        raw_data.append(df)\n",
    "\n",
    "        stat_df = files.eval_stats_dataframe(True)\n",
    "        stat_df = stat_df.assign(object=directories.get_filename())\n",
    "        stat_data.append(stat_df)\n",
    "        \n",
    "\n",
    "\n",
    "dataframe = pd.concat(raw_data, axis=0, ignore_index=True)\n",
    "statsframe = pd.concat(stat_data, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statsframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category = 'filename'\n",
    "# categories = pd.unique(dataframe[category])\n",
    "# medians = {category: [], \"median\": [], \"path\": []}\n",
    "# for cat in categories:\n",
    "#     mask = dataframe[category] == cat\n",
    "#     median = dataframe[mask][[\"eval_loss\"]].median()\n",
    "#     medians[category].append(cat)\n",
    "#     medians[\"median\"].append(median.item())\n",
    "#     medians[\"path\"].append(dataframe[mask][\"path\"].to_list()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# medians[\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# medians = pd.DataFrame(medians)\n",
    "statsframe.sort_values(by='median', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = dataframe['object'] == 'hammer'\n",
    "# stat_mask = statsframe['object'] == 'hammer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size':5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10,40))\n",
    "g = sns.catplot(\n",
    "    data=dataframe,\n",
    "    x=\"params\",\n",
    "    y=\"eval_loss\",\n",
    "    hue=\"object\",\n",
    "    kind=\"box\",\n",
    "    errorbar=\"sd\",\n",
    "    aspect=2,\n",
    "    legend='brief',\n",
    "    order=statsframe['params'],\n",
    "    # hue_order=medians[category],\n",
    ")\n",
    "g.ax.tick_params(axis=\"x\", rotation=90)\n",
    "g.ax.set_title(f\"PSO GridSearch ordered by median eval loss\")\n",
    "\n",
    "g.ax.autoscale_view()\n",
    "g.ax.autoscale()\n",
    "g.figure.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(medians[cat].to_list())\n",
    "\n",
    "# best = MealLog.load(files.root +'/'+ medians[cat].to_list()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx, file_path in enumerate(statsframe['path'].to_list()):\n",
    "    root = files.root\n",
    "    log = MealLog.load(file_path)\n",
    "    params = log.alg_params\n",
    "    if params['empire_count'] == 7 and params['revolution_prob'] == 0.4 and params['revolution_rate'] == 0.4:\n",
    "        print(f\"position={idx} - {log.alg_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import cv2 as cv\n",
    "\n",
    "from view_sampler import *\n",
    "from algs import *\n",
    "\n",
    "import loss_funcs\n",
    "from evaluate import eval_funcs\n",
    "\n",
    "from evaluate.dataset import Dataset\n",
    "from evaluate.eval_log import MealLog\n",
    "from evaluate.evaluator import Evaluator\n",
    "from evaluate.dataset import Dataset\n",
    "from utils.visualize import *\n",
    "from utils.concurrent import TqdmPool, silence_output\n",
    "\n",
    "from main2 import evaluate\n",
    "\n",
    "import mealpy\n",
    "\n",
    "\n",
    "OBJECT_NAMES = [\"airplane\", \"hammer\", \"mug\"]\n",
    "\n",
    "PARAMS: dict[str, dict[str, list]] = {\n",
    "    mealpy.swarm_based.PSO.OriginalPSO.__name__: {\n",
    "        \"c1\": [1, 2.05, 3],\n",
    "        \"c2\": [1, 2.05, 3],\n",
    "        \"w\": [0.2, 0.4, 0.8],\n",
    "    },\n",
    "\n",
    "    mealpy.human_based.ICA.OriginalICA.__name__: {\n",
    "        \"empire_count\": [4, 7, 10],\n",
    "        \"assimilation_coeff\": [1.5, 2.5],\n",
    "        \"revolution_prob\": np.linspace(0.02, 0.4, 3),\n",
    "        \"revolution_rate\": np.linspace(0.05, 0.4, 3),\n",
    "        \"revolution_step_size\": np.linspace(0.05, 0.3, 3),\n",
    "    },\n",
    "    mealpy.human_based.SARO.OriginalSARO.__name__: {\n",
    "        \"se\": [0.3, 0.5, 0.7],\n",
    "        \"mu\": [5, 10, 15, 20],\n",
    "    },\n",
    "\n",
    "    mealpy.evolutionary_based.DE.OriginalDE.__name__: {\"strategy\": range(6)},\n",
    "    mealpy.math_based.PSS.OriginalPSS.__name__: {\n",
    "        \"acceptance_rate\": [0.8, 0.9, 0.95],\n",
    "    },\n",
    "    mealpy.math_based.HC.OriginalHC.__name__: {\"neighbour_size\": [50, 200, 700, 950]},\n",
    "}\n",
    "\n",
    "\n",
    "OPTIMIZERS = [\n",
    "    mealpy.swarm_based.PSO.OriginalPSO,\n",
    "    mealpy.swarm_based.MSA.OriginalMSA,\n",
    "    mealpy.swarm_based.SCSO.OriginalSCSO,\n",
    "    mealpy.physics_based.SA.OriginalSA,\n",
    "    mealpy.physics_based.EVO.OriginalEVO,\n",
    "    mealpy.physics_based.EFO.DevEFO,\n",
    "    mealpy.physics_based.EO.ModifiedEO,\n",
    "    mealpy.human_based.ICA.OriginalICA,\n",
    "    mealpy.human_based.FBIO.DevFBIO,\n",
    "    mealpy.human_based.SARO.OriginalSARO,\n",
    "    mealpy.evolutionary_based.GA.BaseGA,\n",
    "    mealpy.evolutionary_based.CRO.OCRO,\n",
    "    mealpy.evolutionary_based.DE.OriginalDE,\n",
    "    mealpy.math_based.PSS.OriginalPSS,\n",
    "    mealpy.math_based.SCA.DevSCA,\n",
    "    mealpy.math_based.HC.OriginalHC,\n",
    "]\n",
    "\n",
    "\n",
    "OBJ_LOCATION = (0, 1.3, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exec = TqdmPool(4)\n",
    "\n",
    "run_config = MealRunConfig(time_limit=15, silent=True, seed=0)\n",
    "\n",
    "dataset = Dataset.create_random(location=OBJ_LOCATION, num_samples=20, seed=1)\n",
    "\n",
    "results = []\n",
    "\n",
    "tasks = []\n",
    "\n",
    "for optimizer_type in OPTIMIZERS:\n",
    "\n",
    "    optimizer_params = PARAMS[optimizer_type.__name__]\n",
    "\n",
    "    for param_config in product(*optimizer_params.values()):\n",
    "        if len(param_config) == 0:\n",
    "            continue\n",
    "\n",
    "        kwargs = {}\n",
    "        for i, param_name in enumerate(optimizer_params.keys()):\n",
    "            kwargs[param_name] = param_config[i]\n",
    "\n",
    "        try:\n",
    "            optimizer = optimizer_type()\n",
    "            optimizer.set_parameters(kwargs)\n",
    "\n",
    "            for obj_name in OBJECT_NAMES:\n",
    "\n",
    "                task = exec.submit(\n",
    "                    evaluate,\n",
    "                    optimizer=optimizer,\n",
    "                    run_config=run_config,\n",
    "                    obj_name=obj_name,\n",
    "                    eval_positions=dataset,\n",
    "                    log_folder=f\"grid_search/{obj_name}\",\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to create optimizer {optimizer_type.__name__} with params {kwargs}\")\n",
    "            print(str(e))\n",
    "\n",
    "exec.shutdown(wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec.shutdown(wait=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
