{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from view_sampler import ViewSampler, CameraConfig\n",
    "from manipulated_object import ObjectPosition\n",
    "from utils.orient import OrientUtils\n",
    "from evaluate.evaluator import Evaluator\n",
    "import loss_funcs\n",
    "import cv2 as cv\n",
    "\n",
    "from utils.image import ImageUtils\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LOCATION = (0, 1.3, 0.3)\n",
    "\n",
    "LOSS_FUNCTIONS = [\n",
    "    loss_funcs.IOU(),\n",
    "    loss_funcs.MSE(),\n",
    "    loss_funcs.NormMSE(norm=\"euclidean\"),\n",
    "    loss_funcs.WeightedSum(loss_funcs.IOU(), loss_funcs.NormMSE(norm=\"euclidean\")),\n",
    "    loss_funcs.MutualInformation(bins=50),\n",
    "    loss_funcs.PeakSignalNoiseRatio(),\n",
    "    loss_funcs.StructuralSimilarity(),\n",
    "    loss_funcs.HausdorffDistance(),\n",
    "    loss_funcs.AdaptedRandError(),\n",
    "    loss_funcs.VariationOfInformation(),\n",
    "]\n",
    "\n",
    "\n",
    "OBJECTS = [\"airplane\", \"hammer\", \"hand\", \"headphones\", \"mouse\", \"mug\", \"stapler\", \"toothpaste\"]\n",
    "\n",
    "ZFAR = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_viewer(obj_name: str, is_sim: bool = True) -> ViewSampler:\n",
    "    location = (INIT_LOCATION[0], INIT_LOCATION[2] - 1.3, INIT_LOCATION[2])\n",
    "    cam_config = CameraConfig(location, rotation=(np.pi / 2, 0, 0), fov=30, zfar=ZFAR)\n",
    "    if is_sim:\n",
    "        viewer = ViewSampler(f\"data/{obj_name}/world_sim.xml\", cam_config, simulation_time=0)\n",
    "    else:\n",
    "        viewer = ViewSampler(f\"data/{obj_name}/world.xml\", cam_config, simulation_time=0)\n",
    "    return viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_positions(count: int, ) -> list[ObjectPosition]:\n",
    "    orients = OrientUtils.generate_random(count)\n",
    "    positions = [ObjectPosition(orient, INIT_LOCATION) for orient in orients]\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_views(viewer: ViewSampler, pos1: ObjectPosition, pos2: ObjectPosition, depth: bool) -> tuple[np.ndarray, np.ndarray]:\n",
    "    img1, _ = viewer.get_view_cropped(pos1, depth=depth, allow_simulation=False)\n",
    "    img2, _ = viewer.get_view_cropped(pos2, depth=depth, allow_simulation=False)\n",
    "    return img1, img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200\n",
    "positions1 = generate_positions(N)\n",
    "positions2 = generate_positions(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "count = 0\n",
    "\n",
    "for obj_name in tqdm(OBJECTS):\n",
    "    with create_viewer(obj_name) as viewer:\n",
    "        for pos1, pos2 in tqdm(zip(positions1, positions2), total=N):\n",
    "            img1, img2 = get_views(viewer, pos1, pos2, depth=True)\n",
    "            pad_shape = np.maximum(img1.shape, img2.shape)\n",
    "            img1 = ImageUtils.pad_to_shape(img1, pad_shape, pad_value=0)\n",
    "            img2 = ImageUtils.pad_to_shape(img2, pad_shape, pad_value=0)\n",
    "            both = (img1 > 0) & (img2 > 0)\n",
    "\n",
    "            total += np.sum(np.abs(img1[both] - img2[both]))\n",
    "            count += np.sum(both)\n",
    "\n",
    "print(total / count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import eval_funcs\n",
    "from utils.image import ImageUtils\n",
    "\n",
    "eval_func = eval_funcs.XorDiff(0.1)\n",
    "eval_results = []\n",
    "\n",
    "for obj_name in tqdm(OBJECTS):\n",
    "    with create_viewer(obj_name) as sim_viewer:\n",
    "        for pos1, pos2 in tqdm(zip(positions1, positions2), total=N):\n",
    "            img1, img2 = get_views(sim_viewer, pos1, pos2, depth=True)\n",
    "            result = eval_func(img1, img2)\n",
    "            eval_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_results = defaultdict(list)\n",
    "\n",
    "for obj_name in tqdm(OBJECTS):\n",
    "    with create_viewer(obj_name) as sim_viewer:\n",
    "        for pos1, pos2 in tqdm(zip(positions1, positions2), total=N):\n",
    "            img1, img2 = get_views(sim_viewer, pos1, pos2, depth=False)\n",
    "            for loss_func in LOSS_FUNCTIONS:\n",
    "                result = loss_func(img1, img2)\n",
    "                loss_results[type(loss_func).__name__].append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, loss_vals in loss_results.items():\n",
    "    eval_vals = np.asanyarray(eval_results)\n",
    "    loss_vals = np.asanyarray(loss_vals)\n",
    "    print(k, np.corrcoef(eval_vals, loss_vals)[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "font = {\"weight\": \"normal\", \"size\": 10}\n",
    "\n",
    "plt.rc(\"font\", **font)\n",
    "plt.rcParams[\"text.usetex\"] = False\n",
    "\n",
    "plt.cla()\n",
    "fig, axes = plt.subplots(4, 3, sharex=False, figsize=(20, 20))\n",
    "\n",
    "for i, (loss, values) in enumerate(loss_results.items()):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    ax.set_xlabel(\"XorDiff\")\n",
    "    ax.set_ylabel(loss)\n",
    "    ax.set_title(f\"{loss} Objective Function\", fontweight=\"bold\")\n",
    "\n",
    "    x = eval_results\n",
    "    y = np.polyval(np.polyfit(x, values, 1), x)\n",
    "\n",
    "    ax.plot(x, values, \".\", label=loss, markersize=6)\n",
    "    ax.plot(x, y, \":\", linewidth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algs.uniform_sampling import UniformSampling\n",
    "from evaluate import eval_funcs\n",
    "\n",
    "alg_config = UniformSampling.Config(time_limit=1000, min_samples=343, randomized=False, silent=True)\n",
    "\n",
    "eval_positions = generate_positions(75)\n",
    "\n",
    "results = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "SELECTED_LOSSES = [\n",
    "    loss_funcs.IOU(),\n",
    "    loss_funcs.WeightedSum(loss_funcs.IOU(), loss_funcs.NormMSE(norm=\"euclidean\")),\n",
    "    loss_funcs.NormMSE(norm=\"euclidean\"),\n",
    "    loss_funcs.MutualInformation(bins=100),\n",
    "    loss_funcs.HausdorffDistance(),\n",
    "]\n",
    "\n",
    "for obj_name in tqdm(OBJECTS):\n",
    "    with create_viewer(obj_name, True) as sim_viewer, create_viewer(obj_name, False) as world_viewer:\n",
    "        for loss_func in SELECTED_LOSSES:\n",
    "            alg = UniformSampling(sim_viewer, loss_func=loss_func)\n",
    "            evaluator = Evaluator(world_viewer, eval_func=eval_funcs.XorDiff(0.1))\n",
    "            losses = evaluator.evaluate(alg, alg_config, eval_positions)\n",
    "            results[obj_name][type(loss_func).__name__].extend(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.keys())\n",
    "print(results[results.keys()[0]].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "for loss, eval_values in results.items():\n",
    "    print(f\"{loss}: {statistics.mean(eval_values)}\")\n",
    "    print(f\"{loss}: {statistics.median(eval_values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "font = {'weight' : 'normal',\n",
    "        'size'   : 20}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "ax.set_title('Evaluation with Equidistant Sampling Strategy and Different Objective Functions', fontweight='bold')\n",
    "ax.boxplot(results.values(), labels=results.keys(), sym=\"\", patch_artist=False, autorange=True)\n",
    "ax.set_ylabel('XorDiff')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robo-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
