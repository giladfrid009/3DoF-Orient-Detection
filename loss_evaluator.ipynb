{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from view_sampler import ViewSampler, CameraConfig\n",
    "from manipulated_object import ObjectPosition\n",
    "from utils.orient import OrientUtils\n",
    "from evaluate.evaluator import Evaluator\n",
    "import loss_funcs\n",
    "import cv2 as cv\n",
    "\n",
    "from utils.image import ImageUtils\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LOCATION = (0, 1.3, 0.3)\n",
    "\n",
    "LOSS_FUNCTIONS = [\n",
    "    loss_funcs.IOU(),\n",
    "    loss_funcs.MSE(),\n",
    "    loss_funcs.NormMSE(norm=\"euclidean\"),\n",
    "    loss_funcs.WeightedSum(loss_funcs.IOU(), loss_funcs.NormMSE(norm=\"euclidean\")),\n",
    "    loss_funcs.MutualInformation(bins=100),\n",
    "    loss_funcs.PeakSignalNoiseRatio(),\n",
    "    loss_funcs.StructuralSimilarity(),\n",
    "    loss_funcs.HausdorffDistance(),\n",
    "    loss_funcs.AdaptedRandError(),\n",
    "    loss_funcs.VariationOfInformation(),\n",
    "]\n",
    "\n",
    "OBJECTS = [\"airplane\", \"hammer\", \"hand\", \"headphones\", \"mouse\", \"mug\", \"stapler\", \"toothpaste\"]\n",
    "\n",
    "ZFAR = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_viewer(obj_name: str, is_sim: bool = True) -> ViewSampler:\n",
    "    location = (INIT_LOCATION[0], INIT_LOCATION[2] - 1.3, INIT_LOCATION[2])\n",
    "    cam_config = CameraConfig(location, rotation=(np.pi / 2, 0, 0), fov=30, zfar=ZFAR)\n",
    "    if is_sim:\n",
    "        viewer = ViewSampler(f\"data/{obj_name}/world_sim.xml\", cam_config, simulation_time=0)\n",
    "    else:\n",
    "        viewer = ViewSampler(f\"data/{obj_name}/world.xml\", cam_config, simulation_time=0)\n",
    "    return viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_positions(count: int, ) -> list[ObjectPosition]:\n",
    "    orients = OrientUtils.generate_random(count)\n",
    "    positions = [ObjectPosition(orient, INIT_LOCATION) for orient in orients]\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_views(viewer: ViewSampler, pos1: ObjectPosition, pos2: ObjectPosition, depth: bool) -> tuple[np.ndarray, np.ndarray]:\n",
    "    img1, _ = viewer.get_view_cropped(pos1, depth=depth, allow_simulation=False)\n",
    "    img2, _ = viewer.get_view_cropped(pos2, depth=depth, allow_simulation=False)\n",
    "    return img1, img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib qt\n",
    "\n",
    "def heatmap(data, row_labels, col_labels, ax=None,\n",
    "            cbar_kw=None, cbarlabel=\"\", **kwargs):\n",
    "    \"\"\"\n",
    "    Create a heatmap from a numpy array and two lists of labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data\n",
    "        A 2D numpy array of shape (M, N).\n",
    "    row_labels\n",
    "        A list or array of length M with the labels for the rows.\n",
    "    col_labels\n",
    "        A list or array of length N with the labels for the columns.\n",
    "    ax\n",
    "        A `matplotlib.axes.Axes` instance to which the heatmap is plotted.  If\n",
    "        not provided, use current axes or create a new one.  Optional.\n",
    "    cbar_kw\n",
    "        A dictionary with arguments to `matplotlib.Figure.colorbar`.  Optional.\n",
    "    cbarlabel\n",
    "        The label for the colorbar.  Optional.\n",
    "    **kwargs\n",
    "        All other arguments are forwarded to `imshow`.\n",
    "    \"\"\"\n",
    "\n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "        ax = plt.gca()\n",
    "\n",
    "    if cbar_kw is None:\n",
    "        cbar_kw = {}\n",
    "\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
    "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
    "\n",
    "    # Show all ticks and label them with the respective list entries.\n",
    "    ax.set_xticks(np.arange(data.shape[1]), labels=col_labels)\n",
    "    ax.set_yticks(np.arange(data.shape[0]), labels=row_labels)\n",
    "\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    ax.tick_params(top=True, bottom=False,\n",
    "                   labeltop=True, labelbottom=False)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=-30, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Turn spines off and create white grid.\n",
    "    ax.spines[:].set_visible(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[1]+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(data.shape[0]+1)-.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "    for i in range(len(col_labels)):\n",
    "        for j in range(len(row_labels)):\n",
    "            text = ax.text(j, i, round(data[i, j],2),\n",
    "                        ha=\"center\", va=\"center\", color=\"w\")\n",
    "            \n",
    "    return im, cbar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 24\n",
    "\n",
    "init_pos = np.array([0,0,0.3])\n",
    "uni_orients = [list(init_pos)]\n",
    "\n",
    "q = np.array([1, 0, 0])\n",
    "delta = np.linspace(0, np.pi/2, num=n+1)\n",
    "\n",
    "for i in range(n):\n",
    "    uni_orients.append(list(init_pos + delta[i+1]*q))\n",
    "\n",
    "uni_orients = OrientUtils.generate_random(20)\n",
    "uni_positions = [ObjectPosition(orient, INIT_LOCATION) for orient in uni_orients]\n",
    "len(uni_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_name = OBJECTS[1]\n",
    "viewer = create_viewer(object_name, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06391369,  0.12604662,  0.62187402],\n",
       "       [ 0.4151444 , -1.04497172, -0.87917655],\n",
       "       [-0.04795201,  0.10837436,  0.27279596],\n",
       "       [ 1.80137962,  0.97411222, -1.72845657],\n",
       "       [ 1.72888035,  0.65635599,  1.24976202],\n",
       "       [ 0.0890371 ,  0.00533704, -0.16308311],\n",
       "       [ 0.42215688,  0.36192199,  0.54563747],\n",
       "       [-0.27267751, -0.19914269, -0.68876737],\n",
       "       [-0.30034492, -0.73378504, -0.36727457],\n",
       "       [-0.75465701, -0.91582453,  0.09080581],\n",
       "       [-1.27616636, -0.01714469,  0.38668262],\n",
       "       [-0.13833163,  0.05613834,  0.5324142 ],\n",
       "       [ 0.53832904, -1.16726947, -0.36101368],\n",
       "       [-0.03250202,  0.02793212,  0.0108574 ],\n",
       "       [ 2.96904739, -0.23666068,  1.15553598],\n",
       "       [-3.10256847,  0.21701548,  1.5248829 ],\n",
       "       [-1.79336589, -1.32961435,  1.38045425],\n",
       "       [-2.67400153,  0.36513492,  1.19786224],\n",
       "       [ 0.94947097,  0.54207453,  0.4006913 ],\n",
       "       [ 1.18953515,  0.13478557, -1.54422532]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_orients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nrows, ncols = (4, 5)\n",
    "fig, axes = plt.subplots(nrows, ncols)\n",
    "for idx, pos in enumerate(uni_positions):\n",
    "    col = idx%ncols\n",
    "    row = math.floor(idx/ncols)\n",
    "    ax = axes[row, col]\n",
    "    ax.imshow(viewer.get_view_cropped(pos, allow_simulation=False, depth=False)[0])\n",
    "    # print(pos)\n",
    "    ax.set_title(f\"{idx}::{np.round(pos.orientation, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pos1, pos2 \u001b[38;5;129;01min\u001b[39;00m product(uni_positions, uni_positions):\n\u001b[1;32m      9\u001b[0m     img1, img2 \u001b[38;5;241m=\u001b[39m get_views(viewer, pos1, pos2, depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 10\u001b[0m     result \u001b[38;5;241m=\u001b[39m eval_func(img1, img2)\n\u001b[1;32m     11\u001b[0m     eval_results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m     12\u001b[0m results \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(eval_results)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mlen\u001b[39m(uni_positions), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Technion/1 Courses/Robotics/Robotics-Proj/evaluate/eval_funcs.py:18\u001b[0m, in \u001b[0;36mEvalFunc.__call__\u001b[0;34m(self, depth_truth, depth_other)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, depth_truth: np\u001b[38;5;241m.\u001b[39mndarray, depth_other: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    Calculate the loss metric between two depth maps. The more similar the images, the lower the loss value.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m        float | list[float]: The calculated loss value(s).\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m depth_truth\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m depth_truth\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m depth_other\u001b[38;5;241m.\u001b[39mndim\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m depth_truth\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m depth_other\u001b[38;5;241m.\u001b[39mshape:\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate XorDiff \n",
    "from evaluate import eval_funcs\n",
    "from itertools import product\n",
    "\n",
    "eval_func = eval_funcs.XorDiff(0.1)\n",
    "eval_results = []\n",
    "\n",
    "for pos1, pos2 in product(uni_positions, uni_positions):\n",
    "    img1, img2 = get_views(viewer, pos1, pos2, depth=True)\n",
    "    result = eval_func(img1, img2)\n",
    "    eval_results.append(result)\n",
    "results = np.array(eval_results).reshape(len(uni_positions), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(results, range(len(uni_positions)), range(len(uni_positions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(x=delta, y=results[0])\n",
    "\n",
    "ax.set_title(\"XorDiff as function of rotation\")\n",
    "ax.set_xlabel(\"angel change (radians)\")\n",
    "ax.set_ylabel(\"XorDiff value\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "def save(file_path: str, obj):\n",
    "    Path(file_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"error saving object to pickle file: {e}\")\n",
    "\n",
    "def load(file_path: str) -> object:\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"file does not exist: {file_path}\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"error loading object from pickle file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200\n",
    "positions1 = generate_positions(N)\n",
    "positions2 = generate_positions(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import eval_funcs\n",
    "from utils.image import ImageUtils\n",
    "\n",
    "eval_func = eval_funcs.XorDiff(0.1)\n",
    "eval_results = []\n",
    "\n",
    "for obj_name in tqdm(OBJECTS):\n",
    "    with create_viewer(obj_name) as sim_viewer:\n",
    "        for pos1, pos2 in tqdm(zip(positions1, positions2), total=N):\n",
    "            img1, img2 = get_views(sim_viewer, pos1, pos2, depth=True)\n",
    "            result = eval_func(img1, img2)\n",
    "            eval_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_results = defaultdict(list)\n",
    "\n",
    "for obj_name in tqdm(OBJECTS):\n",
    "    with create_viewer(obj_name) as sim_viewer:\n",
    "        for pos1, pos2 in tqdm(zip(positions1, positions2), total=N):\n",
    "            img1, img2 = get_views(sim_viewer, pos1, pos2, depth=False)\n",
    "            for loss_func in LOSS_FUNCTIONS:\n",
    "                result = loss_func(img1, img2)\n",
    "                loss_results[type(loss_func).__name__].append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, loss_vals in loss_results.items():\n",
    "    eval_vals = np.asanyarray(eval_results)\n",
    "    loss_vals = np.asanyarray(loss_vals)\n",
    "    print(k, np.corrcoef(eval_vals, loss_vals)[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "font = {'weight' : 'normal',\n",
    "        'size'   : 10}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rcParams['text.usetex'] = False\n",
    "\n",
    "plt.cla()\n",
    "fig, axes = plt.subplots(4, 3, sharex=False, figsize=(20, 20))\n",
    "\n",
    "for i, (loss, values) in enumerate(loss_results.items()):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    ax.set_xlabel(\"XorDiff\")\n",
    "    ax.set_ylabel(loss)\n",
    "    ax.set_title(f\"{loss} Objective Function\", fontweight='bold')\n",
    "\n",
    "    x = eval_results\n",
    "    y = np.polyval(np.polyfit(x, values, 1), x)\n",
    "\n",
    "    ax.plot(x, values, '.', label=loss, markersize=6)\n",
    "    ax.plot(x, y, \":\", linewidth=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algs.uniform_sampling import UniformSampling\n",
    "from evaluate import eval_funcs\n",
    "\n",
    "alg_config = UniformSampling.Config(time_limit=1000, min_samples=343, randomized=False, silent=True)\n",
    "\n",
    "eval_positions = generate_positions(75)\n",
    "\n",
    "results = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "SELECTED_LOSSES = [\n",
    "    loss_funcs.IOU(),\n",
    "    loss_funcs.NormMSE(norm=\"euclidean\"),\n",
    "    loss_funcs.MutualInformation(bins=100),\n",
    "    loss_funcs.HausdorffDistance(),\n",
    "]\n",
    "\n",
    "for obj_name in tqdm(OBJECTS):\n",
    "    with create_viewer(obj_name, True) as sim_viewer, create_viewer(obj_name, False) as world_viewer:\n",
    "        for loss_func in SELECTED_LOSSES:\n",
    "            alg = UniformSampling(sim_viewer, loss_func=loss_func)\n",
    "            evaluator = Evaluator(world_viewer, eval_func=eval_funcs.XorDiff(0.1))\n",
    "            losses = evaluator.evaluate(alg, alg_config, eval_positions)\n",
    "            results[obj_name][type(loss_func).__name__].extend(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.keys())\n",
    "print(results[results.keys()[0]].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "for loss, eval_values in results.items():\n",
    "    print(f\"{loss}: {statistics.mean(eval_values)}\")\n",
    "    print(f\"{loss}: {statistics.median(eval_values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "font = {'weight' : 'normal',\n",
    "        'size'   : 20}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "ax.set_title('Evaluation with Equidistant Sampling Strategy and Different Objective Functions', fontweight='bold')\n",
    "ax.boxplot(results.values(), labels=results.keys(), sym=\"\", patch_artist=False, autorange=True)\n",
    "ax.set_ylabel('XorDiff')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robo-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
