{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from view_sampler import ViewSampler, CameraConfig\n",
    "from manipulated_object import ObjectPosition\n",
    "from utils.orient import OrientUtils\n",
    "from algs.uniform_sampling import UniformSampling\n",
    "from evaluate.evaluator import Evaluator\n",
    "import loss_funcs\n",
    "import cv2 as cv\n",
    "\n",
    "from utils.image import ImageUtils\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LOCATION = (0, 1.3, 0.3)\n",
    "\n",
    "LOSS_FUNCTIONS = [\n",
    "    loss_funcs.IOU(),\n",
    "    loss_funcs.MSE(),\n",
    "    loss_funcs.NormMSE(norm=\"euclidean\"),\n",
    "    loss_funcs.MutualInformation(bins=100),\n",
    "    loss_funcs.PeakSignalNoiseRation(),\n",
    "    loss_funcs.StructuralSimilarity(),\n",
    "    loss_funcs.HausdorffDistance(),\n",
    "    loss_funcs.AdaptedRandError(),\n",
    "    loss_funcs.VariationOfInformation(),\n",
    "]\n",
    "\n",
    "OBJECTS = [\"airplane\", \"hammer\", \"hand\", \"headphones\", \"mouse\", \"mug\", \"stapler\", \"toothpaste\"]\n",
    "\n",
    "ZFAR = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_viewer(obj_name: str) -> ViewSampler:\n",
    "    location = (INIT_LOCATION[0], INIT_LOCATION[2] - 1.3, INIT_LOCATION[2])\n",
    "    cam_config = CameraConfig(location, rotation=(np.pi / 2, 0, 0), fov=30, zfar=ZFAR)\n",
    "    sim_viewer = ViewSampler(f\"data/{obj_name}/world_sim.xml\", cam_config, simulation_time=0)\n",
    "    return sim_viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_positions(count: int, ) -> list[ObjectPosition]:\n",
    "    orients = OrientUtils.generate_random(count)\n",
    "    positions = [ObjectPosition(orient, INIT_LOCATION) for orient in orients]\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_views(viewer: ViewSampler, pos1: ObjectPosition, pos2: ObjectPosition, depth: bool) -> tuple[np.ndarray, np.ndarray]:\n",
    "    img1, _ = viewer.get_view_cropped(pos1, depth=depth, allow_simulation=False)\n",
    "    img2, _ = viewer.get_view_cropped(pos2, depth=depth, allow_simulation=False)\n",
    "    pad_shape = np.maximum(img1.shape, img2.shape)\n",
    "    img1 = ImageUtils.pad_to_shape(img1, pad_shape)\n",
    "    img2 = ImageUtils.pad_to_shape(img2, pad_shape)\n",
    "    return img1, img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "def save(file_path: str, obj):\n",
    "    Path(file_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"error saving object to pickle file: {e}\")\n",
    "\n",
    "def load(file_path: str) -> object:\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"file does not exist: {file_path}\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"error loading object from pickle file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200\n",
    "positions1 = generate_positions(N)\n",
    "positions2 = generate_positions(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import eval_funcs\n",
    "from utils.image import ImageUtils\n",
    "\n",
    "eval_func = eval_funcs.XorDiff(0.1)\n",
    "eval_results = []\n",
    "\n",
    "for obj_name in tqdm(OBJECTS):\n",
    "    with setup_viewer(obj_name) as viewer:\n",
    "        for pos1, pos2 in tqdm(zip(positions1, positions2), total=N):\n",
    "            img1, img2 = get_views(viewer, pos1, pos2, depth=True)\n",
    "            result = eval_func(img1, img2)\n",
    "            eval_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_results = defaultdict(list)\n",
    "\n",
    "for obj_name in tqdm(OBJECTS):\n",
    "    with setup_viewer(obj_name) as viewer:\n",
    "        for pos1, pos2 in tqdm(zip(positions1, positions2), total=N):\n",
    "            img1, img2 = get_views(viewer, pos1, pos2, depth=False)\n",
    "            for loss_func in LOSS_FUNCTIONS:\n",
    "                result = loss_func(img1, img2)\n",
    "                loss_results[type(loss_func).__name__].append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, loss_vals in loss_results.items():\n",
    "    eval_vals = np.asanyarray(eval_results)\n",
    "    loss_vals = np.asanyarray(loss_vals)\n",
    "    print(k, np.corrcoef(eval_vals, loss_vals)[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "font = {'weight' : 'normal',\n",
    "        'size'   : 20}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rcParams['text.usetex'] = False\n",
    "\n",
    "for i, (loss, values) in enumerate(loss_results.items()):\n",
    "    fig = plt.figure(i, figsize=(9, 6))\n",
    "    fig.clear()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlabel(\"XorDiff\")\n",
    "    ax.set_ylabel(loss)\n",
    "    ax.set_title(f\"{loss} Objective Function\")\n",
    "\n",
    "    x = eval_results\n",
    "    y = np.polyval(np.polyfit(x, values, 1), x)\n",
    "\n",
    "    ax.plot(x, y)\n",
    "\n",
    "    plt.plot(eval_results, values, '.', label=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orients = OrientUtils.generate_random(30)\n",
    "\n",
    "INIT_LOCATION = (0, 1.3, 0.3)\n",
    "cam_config = CameraConfig(location=(0, 0, 0.3), rotation=(np.pi / 2, 0, 0), fov=30)\n",
    "sim_viewer = ViewSampler(\"data/stapler/world_sim.xml\", cam_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()\n",
    "\n",
    "orients1 = OrientUtils.generate_random(5000)\n",
    "orients2 = OrientUtils.generate_random(5000)\n",
    "\n",
    "loss_dict = defaultdict(list)\n",
    "\n",
    "INIT_LOCATION = (0, 1.3, 0.3)\n",
    "cam_config = CameraConfig(location=(0, 0, 0.3), rotation=(np.pi / 2, 0, 0), fov=30)\n",
    "sim_viewer = ViewSampler(\"data/mug/world_sim.xml\", cam_config)\n",
    "\n",
    "for ori1, ori2 in tqdm(zip(orients1, orients2), total=len(orients1)):\n",
    "    for loss in LOSS_FUNCTIONS:    \n",
    "        pos1 = ObjectPosition(ori1, INIT_LOCATION)\n",
    "        pos2 = ObjectPosition(ori2, INIT_LOCATION)\n",
    "\n",
    "        rgb1, _ = sim_viewer.get_view_cropped(pos1, depth=False, allow_simulation=False)\n",
    "        rgb2, _ = sim_viewer.get_view_cropped(pos2, depth=False, allow_simulation=False)\n",
    "\n",
    "        pad_shape = np.maximum(rgb1.shape, rgb2.shape)\n",
    "        rgb1 = ImageUtils.pad_to_shape(rgb1, pad_shape)\n",
    "        rgb2 = ImageUtils.pad_to_shape(rgb2, pad_shape)\n",
    "\n",
    "        loss_val = loss(rgb1, rgb2)\n",
    "        loss_dict[type(loss).__name__].append(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LOCATION = (0, 1.3, 0.3)\n",
    "cam_config = CameraConfig(location=(0, 0, 0.3), rotation=(np.pi / 2, 0, 0), fov=30)\n",
    "sim_viewer = ViewSampler(\"data/mug/world_sim.xml\", cam_config)\n",
    "\n",
    "loss_dict = load(\"loss_dict\")\n",
    "orients1 = load(\"ori1\")\n",
    "orients2 = load(\"ori2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_values = []\n",
    "\n",
    "xor_eval = eval_funcs.XorDiff(penalty=1.0, p_norm=1.0)\n",
    "\n",
    "for ori1, ori2 in tqdm(zip(orients1, orients2), total=len(orients1)):\n",
    "    pos1 = ObjectPosition(ori1, INIT_LOCATION)\n",
    "    pos2 = ObjectPosition(ori2, INIT_LOCATION)\n",
    "\n",
    "    depth1, _ = sim_viewer.get_view_cropped(pos1, depth=True, allow_simulation=False)\n",
    "    depth2, _ = sim_viewer.get_view_cropped(pos2, depth=True, allow_simulation=False)\n",
    "\n",
    "    pad_shape = np.maximum(depth1.shape, depth2.shape)\n",
    "    depth1 = ImageUtils.pad_to_shape(depth1, pad_shape)\n",
    "    depth2 = ImageUtils.pad_to_shape(depth2, pad_shape)\n",
    "\n",
    "    depth1[depth1 > 20] = 0\n",
    "    depth2[depth2 > 20] = 0\n",
    "\n",
    "    eval_val = xor_eval(depth1, depth2)\n",
    "    eval_values.append(eval_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "font = {'weight' : 'normal',\n",
    "        'size'   : 20}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rcParams['text.usetex'] = False\n",
    "\n",
    "for i, (loss, values) in enumerate(loss_dict.items()):\n",
    "    fig = plt.figure(i, figsize=(9, 6))\n",
    "    fig.clear()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlabel(\"XorDiff\")\n",
    "    ax.set_ylabel(loss)\n",
    "    ax.set_title(f\"{loss} Objective Function\")\n",
    "    plt.plot(eval_values, values, '.', label=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_config = CameraConfig(location=(0, 0, 0.3), rotation=(np.pi / 2, 0, 0), fov=30)\n",
    "world_viewer = ViewSampler(\"data/mug/world.xml\", cam_config, simulation_time=0)\n",
    "sim_viewer = ViewSampler(\"data/mug/world_sim.xml\", cam_config)\n",
    "\n",
    "INIT_LOCATION = (0, 1.3, 0.3)\n",
    "random_orientations = OrientUtils.generate_random(200)\n",
    "pos1 = [ObjectPosition(orient, INIT_LOCATION) for orient in random_orientations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_FUNCTIONS = [\n",
    "    loss_funcs.IOU(),\n",
    "    loss_funcs.MSE(),\n",
    "    loss_funcs.NormMSE(norm=\"euclidean\"),\n",
    "    loss_funcs.MutualInformation(bins=100),\n",
    "    loss_funcs.PeakSignalNoiseRation(),\n",
    "    loss_funcs.StructuralSimilarity(),\n",
    "    loss_funcs.HausdorffDistance(),\n",
    "    loss_funcs.AdaptedRandError(),\n",
    "    loss_funcs.VariationOfInformation(),\n",
    "]\n",
    "\n",
    "alg_config = UniformSampling.Config(time_limit=1000, min_samples=343, randomized=False, silent=True)\n",
    "\n",
    "evaluator = Evaluator(world_viewer, eval_func=eval_funcs.NormXorDiff(penalty=2.0, p_norm=\"mse\"))\n",
    "\n",
    "results = dict()\n",
    "\n",
    "for loss in LOSS_FUNCTIONS:\n",
    "    alg = UniformSampling(sim_viewer, loss_func=loss)\n",
    "    alg.register_callback()\n",
    "    eval_values = evaluator.evaluate(alg, alg_config, pos1)\n",
    "    results[type(loss).__name__] = eval_values\n",
    "    print(f\"{type(loss).__name__}: {eval_values}\")\n",
    "\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "for loss, eval_values in results.items():\n",
    "    print(f\"{loss}: {statistics.mean(eval_values)}\")\n",
    "    print(f\"{loss}: {statistics.median(eval_values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"NMSE\"] = results.pop(\"NormMSE\")\n",
    "results[\"NMI\"] = results.pop(\"MutualInformation\")\n",
    "results[\"PSNR\"] = results.pop(\"PeakSignalNoiseRation\")\n",
    "results[\"SSIM\"] = results.pop(\"StructuralSimilarity\")\n",
    "results[\"Hausdorff\"] = results.pop(\"HausdorffDistance\")\n",
    "results[\"ARE\"] = results.pop(\"AdaptedRandError\")\n",
    "results[\"VI\"] = results.pop(\"VariationOfInformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 20}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "ax.set_title('XorDiff Value per UniformSampling and Different Objective Functions')\n",
    "ax.boxplot(results.values(), labels=results.keys(), sym=\"\", patch_artist=False, autorange=True)\n",
    "ax.set_ylabel('XorDiff Value')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robo-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
