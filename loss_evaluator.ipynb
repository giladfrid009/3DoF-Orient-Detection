{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from view_sampler import ViewSampler, CameraConfig\n",
    "from manipulated_object import ObjectPosition\n",
    "from utils.orient import OrientUtils\n",
    "\n",
    "cam_config = CameraConfig(location=(0, 0, 0.1), rotation=(np.pi / 2, 0, 0), fov=30)\n",
    "world_viewer = ViewSampler(\"data/world_mug.xml\", cam_config, simulation_time=0)\n",
    "sim_viewer = ViewSampler(\"data/world_mug_sim.xml\", cam_config)\n",
    "\n",
    "init_location = (0, 1.3, 0.3)\n",
    "random_orientations = OrientUtils.generate_random(512)\n",
    "eval_positions = [ObjectPosition(orient, init_location) for orient in random_orientations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Algorithm: UniformSampling\n",
      "Alg Config: UniformSampling.Config(time_limit=1000, rnd_seed=None, min_samples=343, randomized=False)\n",
      "Loss Function: IOU\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc8f34a2bd549d4b92e2c3497e0e0a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04a7156112248189f07ef339f2ba847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/343 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313156aab9114f258c1a44801de9f724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/343 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37130f73ccc84effb804054783889167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/343 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m loss \u001b[38;5;129;01min\u001b[39;00m loss_functions:\n\u001b[1;32m     27\u001b[0m     alg \u001b[38;5;241m=\u001b[39m UniformSampling(sim_viewer, loss_func\u001b[38;5;241m=\u001b[39mloss)\n\u001b[0;32m---> 28\u001b[0m     eval_losses \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43malg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malg_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_positions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     results[\u001b[38;5;28mtype\u001b[39m(loss)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m] \u001b[38;5;241m=\u001b[39m eval_losses\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(loss)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_losses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/source/Robotics-Proj/evaluate/evaluator.py:56\u001b[0m, in \u001b[0;36mEvaluator.evaluate\u001b[0;34m(self, alg, alg_config, eval_positions)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m position \u001b[38;5;129;01min\u001b[39;00m tqdm(eval_positions, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating: \u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     50\u001b[0m     ref_img, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld_viewer\u001b[38;5;241m.\u001b[39mget_view_cropped(\n\u001b[1;32m     51\u001b[0m         position,\n\u001b[1;32m     52\u001b[0m         depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     53\u001b[0m         allow_simulation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     54\u001b[0m     )\n\u001b[0;32m---> 56\u001b[0m     pred_orient, _ \u001b[38;5;241m=\u001b[39m \u001b[43malg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malg_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     ref_depth, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld_viewer\u001b[38;5;241m.\u001b[39mget_view_cropped(\n\u001b[1;32m     59\u001b[0m         position\u001b[38;5;241m=\u001b[39mposition,\n\u001b[1;32m     60\u001b[0m         depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     61\u001b[0m         allow_simulation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     64\u001b[0m     pred_depth, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld_viewer\u001b[38;5;241m.\u001b[39mget_view_cropped(\n\u001b[1;32m     65\u001b[0m         position\u001b[38;5;241m=\u001b[39mObjectPosition(pred_orient, position\u001b[38;5;241m.\u001b[39mlocation),\n\u001b[1;32m     66\u001b[0m         depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     67\u001b[0m         allow_simulation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     68\u001b[0m     )\n",
      "File \u001b[0;32m~/source/Robotics-Proj/algs/uniform_sampling.py:47\u001b[0m, in \u001b[0;36mUniformSampling.solve\u001b[0;34m(self, ref_img, ref_location, alg_config)\u001b[0m\n\u001b[1;32m     44\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_orient \u001b[38;5;129;01min\u001b[39;00m tqdm_bar:\n\u001b[0;32m---> 47\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_orient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;241m<\u001b[39m lowest_loss:\n\u001b[1;32m     50\u001b[0m         lowest_loss \u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[0;32m~/source/Robotics-Proj/algs/algorithm.py:41\u001b[0m, in \u001b[0;36mAlgorithm.calc_loss\u001b[0;34m(self, ref_location, ref_img, test_orient)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_loss\u001b[39m(\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     37\u001b[0m     ref_location: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m],\n\u001b[1;32m     38\u001b[0m     ref_img: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[1;32m     39\u001b[0m     test_orient: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m],\n\u001b[1;32m     40\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m---> 41\u001b[0m     test_img, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_test_viewer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_view_cropped\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mObjectPosition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_orient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_location\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_simulation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     pad_shape \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(ref_img\u001b[38;5;241m.\u001b[39mshape, test_img\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     47\u001b[0m     ref_img \u001b[38;5;241m=\u001b[39m ImageUtils\u001b[38;5;241m.\u001b[39mpad_to_shape(ref_img, pad_shape)\n",
      "File \u001b[0;32m~/source/Robotics-Proj/view_sampler.py:82\u001b[0m, in \u001b[0;36mViewSampler.get_view_cropped\u001b[0;34m(self, position, depth, margin_factor, allow_simulation)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_view_cropped\u001b[39m(\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     75\u001b[0m     position: ObjectPosition,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m     allow_simulation: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     79\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray, ObjectPosition]:\n\u001b[1;32m     81\u001b[0m     image, position \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_view(position, depth, allow_simulation\u001b[38;5;241m=\u001b[39mallow_simulation)\n\u001b[0;32m---> 82\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[43mImageUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbg_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     x1, y1, x2, y2 \u001b[38;5;241m=\u001b[39m ImageUtils\u001b[38;5;241m.\u001b[39mcalc_bboxes(mask, margin_factor)\n\u001b[1;32m     84\u001b[0m     cropped \u001b[38;5;241m=\u001b[39m image[x1:x2, y1:y2, :]\n",
      "File \u001b[0;32m~/source/Robotics-Proj/utils/image.py:22\u001b[0m, in \u001b[0;36mImageUtils.calc_mask\u001b[0;34m(images, bg_value, orig_dims)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_mask\u001b[39m(images: np\u001b[38;5;241m.\u001b[39mndarray, bg_value: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, orig_dims: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m---> 22\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbg_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m orig_dims:\n\u001b[1;32m     24\u001b[0m         mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbroadcast_to(np\u001b[38;5;241m.\u001b[39mexpand_dims(mask, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), images\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniforge3/envs/robo-proj/lib/python3.11/site-packages/numpy/core/fromnumeric.py:2412\u001b[0m, in \u001b[0;36many\u001b[0;34m(a, axis, out, keepdims, where)\u001b[0m\n\u001b[1;32m   2322\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_any_dispatcher)\n\u001b[1;32m   2323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21many\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2325\u001b[0m \u001b[38;5;124;03m    Test whether any array element along a given axis evaluates to True.\u001b[39;00m\n\u001b[1;32m   2326\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2410\u001b[0m \n\u001b[1;32m   2411\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogical_or\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43many\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2413\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/robo-proj/lib/python3.11/site-packages/numpy/core/fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from algs.uniform_sampling import UniformSampling\n",
    "from evaluate.evaluator import Evaluator\n",
    "from evaluate import eval_funcs\n",
    "import loss_funcs\n",
    "import cv2 as cv\n",
    "\n",
    "\n",
    "loss_functions = [\n",
    "    loss_funcs.IOU(),\n",
    "    loss_funcs.MSE(),\n",
    "    loss_funcs.NormMSE(norm=\"euclidean\"),\n",
    "    loss_funcs.MutualInformation(bins=100),\n",
    "    loss_funcs.PeakSignalNoiseRation(),\n",
    "    loss_funcs.StructuralSimilarity(win_size=None),\n",
    "    loss_funcs.HausdorffDistance(),\n",
    "    loss_funcs.AdaptedRandError(),\n",
    "    loss_funcs.VariationOfInformation(),\n",
    "]\n",
    "\n",
    "alg_config = UniformSampling.Config(time_limit=1000, min_samples=343, randomized=False)\n",
    "\n",
    "evaluator = Evaluator(world_viewer, eval_func=eval_funcs.NormXorDiff(obj_depth=2.0, method=\"mse\"))\n",
    "\n",
    "results = dict()\n",
    "\n",
    "for loss in loss_functions:\n",
    "    alg = UniformSampling(sim_viewer, loss_func=loss)\n",
    "    eval_losses = evaluator.evaluate(alg, alg_config, eval_positions)\n",
    "    results[type(loss).__name__] = eval_losses\n",
    "    print(f\"{type(loss).__name__}: {eval_losses}\")\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robo-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
