{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import torch\n",
    "from camera_simulator import CameraSimulator\n",
    "from camera_utils import xy_axes_to_frame_rotation, get_torch3d_R_T\n",
    "from matplotlib import pyplot as plt\n",
    "from sam_segmentation import SAMSegmentation\n",
    "from utils import (\n",
    "    plot_segmentation_mask,\n",
    "    masks_intersection_batch,\n",
    "    compute_masks_IOU_batch,\n",
    ")\n",
    "from geometric_mesh_segmentation import CameraParameters, get_mesh_segmentation_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageManipulator:\n",
    "    \"\"\"\n",
    "    Image manipulation functions that work both on batched data and single images.\n",
    "    Image batch dim is assumed to be [N, W, H, 3]\n",
    "    Single image dim is assumed to be [W, H, 3]\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def calc_mask(images: np.ndarray, bg_value: int = 0, orig_dims: bool = False) -> np.ndarray:\n",
    "        mask = np.any(images != bg_value, axis=-1)\n",
    "        if orig_dims:\n",
    "            mask = np.broadcast_to(np.expand_dims(mask, axis=-1), images.shape)\n",
    "        return mask\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_bboxes(mask_batch: np.ndarray, margin_factor: float = 1.2) -> np.ndarray:\n",
    "        x = np.any(mask_batch, axis=-1)\n",
    "        y = np.any(mask_batch, axis=-2)\n",
    "\n",
    "        def argmin_argmax(arr: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "            # find smallest and largest indices\n",
    "            imin = np.argmax(arr, axis=-1)\n",
    "            arr = np.flip(arr, axis=-1)\n",
    "            length = arr.shape[-1]\n",
    "            imax = length - np.argmax(arr, axis=-1)\n",
    "\n",
    "            # add margin to the indices\n",
    "            diff = imax - imin\n",
    "            margin = (diff * (margin_factor - 1)).astype(imin.dtype)\n",
    "            imin = imin - margin\n",
    "            imax = imax + margin\n",
    "\n",
    "            # make sure we're within bounds\n",
    "            imin = np.maximum(imin, 0)\n",
    "            imax = np.minimum(imax, length - 1)\n",
    "            return imin, imax\n",
    "\n",
    "        xmin, xmax = argmin_argmax(x)\n",
    "        ymin, ymax = argmin_argmax(y)\n",
    "\n",
    "        return np.stack((xmin, ymin, xmax, ymax), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViewProvider:\n",
    "    def __init__(\n",
    "        self,\n",
    "        world_file: str,\n",
    "        cam_res: tuple[int, int] = (300, 300),\n",
    "        cam_fov: int = 45,\n",
    "        cam_height: float = 0.75,\n",
    "        render_depth: bool = False,\n",
    "    ):\n",
    "        self._camera = CameraSimulator(resolution=cam_res, fovy=cam_fov, world_file=world_file)\n",
    "        self._camera.set_object_position([0, 0, 0])\n",
    "        self._camera_height = cam_height\n",
    "        self._camera_position = [0, 0, cam_height]\n",
    "        self._render_depth = render_depth\n",
    "\n",
    "    def _render_image(self):\n",
    "        if self._render_depth:\n",
    "            return self._camera.render_depth(torch.eye(3), self._camera_position)\n",
    "        return self._camera.render(torch.eye(3), self._camera_position)\n",
    "\n",
    "    def get_view(self, orient: tuple[float, float, float]) -> np.ndarray:\n",
    "        self._camera.set_object_orientation_euler(orient)\n",
    "        image = self._render_image()\n",
    "        return image\n",
    "\n",
    "    def get_view_batch(self, orient_list: list[tuple[float, float, float]]):\n",
    "        image_list = []\n",
    "        for orient in orient_list:\n",
    "            self._camera.set_object_orientation_euler(orient)\n",
    "            image = self._render_image()\n",
    "            image_list.append(image)\n",
    "        return image_list\n",
    "\n",
    "    def get_view_cropped(self, orient: tuple[float, float, float], margin_factor: float = 1.2) -> np.ndarray:\n",
    "        self._camera.set_object_orientation_euler(orient)\n",
    "        image = self._render_image()\n",
    "        mask = ImageManipulator.calc_mask(image, bg_value=0, orig_dims=False)\n",
    "        x1, y1, x2, y2 = ImageManipulator.calc_bboxes(mask, margin_factor)\n",
    "        cropped = image[x1:x2, y1:y2, :]\n",
    "        return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QStandardPaths: wrong permissions on runtime directory /run/user/1000/, 0755 instead of 0700\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m im \u001b[38;5;241m=\u001b[39m viewer\u001b[38;5;241m.\u001b[39mget_view_cropped(orient)\n\u001b[1;32m      7\u001b[0m cv\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m, im)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random_orientations = np.random.uniform(0, 2 * np.pi, size=(100, 3))\n",
    "\n",
    "viewer = ViewProvider(world_file=\"data/world_mug_sim.xml\")\n",
    "\n",
    "for orient in random_orientations:\n",
    "    im = viewer.get_view_cropped(orient)\n",
    "    cv.imshow(\"img\", im)\n",
    "    cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mesh = \"./data/meshes/mug.obj\"\n",
    "scale = 0.02\n",
    "\n",
    "_camera_position = [0.5, -0.5, 1.75]\n",
    "cam_xy_axes = [[0.685, 0.728, 0.000], [-0.487, 0.458, 0.743]]\n",
    "cam_frame_R = xy_axes_to_frame_rotation(cam_xy_axes[0], cam_xy_axes[1])\n",
    "cam_resx, cam_resy = 300, 300\n",
    "cam_fov = 45\n",
    "\n",
    "table_height = 0\n",
    "obj_position_actual = [0, 0, 0.08 + table_height]\n",
    "obj_orientation_actual = [2.1, 0, 1.57]\n",
    "obj_positions = [\n",
    "    [0, 0, 0.08 + table_height],\n",
    "    [0, 0, 0.08 + table_height],\n",
    "    [0, 0, 0.12 + table_height],\n",
    "    [0, 0, 0.12 + table_height],\n",
    "]\n",
    "\n",
    "# range is [0 - 2pi, -pi/2 - pi/2, 0 - 2pi]\n",
    "obj_orientations = [[2.1, 0, 1.57], [0, 0, 1.57], [0, -0.2, 0], [3.14, -0.2, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = np.zeros([cam_resy, cam_resx])\n",
    "\n",
    "cam_sim = CameraSimulator(resolution=(cam_resy, cam_resx), fovy=cam_fov, world_file=\"data/world_mug_sim.xml\")\n",
    "\n",
    "random_orientations = np.random.uniform(0, 2 * np.pi, size=(100, 3))\n",
    "random_position = np.asanyarray(obj_position_actual) + np.random.uniform(-0.1, 0.1, size=(100, 3))\n",
    "\n",
    "images_list = []\n",
    "for position, orient in zip(random_position, random_orientations):\n",
    "    cam_sim.set_object_position(position.tolist())\n",
    "    cam_sim.set_object_orientation_euler(orient)\n",
    "    im = cam_sim.render(torch.eye(3), [0, 0, 1.75])\n",
    "    images_list.append(im)\n",
    "    cv.imshow(\"img\", im)\n",
    "    cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sam to segment actual image and show it\n",
    "cam_sim.set_object_position(obj_position_actual)\n",
    "cam_sim.set_object_orientation_euler(obj_orientation_actual)\n",
    "im_actual = cam_sim.render(cam_frame_R, _camera_position)\n",
    "\n",
    "sam = SAMSegmentation()\n",
    "mask_sam, score = sam.segment_image_center(im_actual, best_out_of_3=True)\n",
    "plot_segmentation_mask(im_actual, mask_sam, mask_alpha=0.95, color=[30, 255, 30])\n",
    "iou = compute_masks_IOU_batch(torch.from_numpy(mask_sam).unsqueeze(0), torch.cat(masks))\n",
    "# save sam mask:\n",
    "np.save(\"./sam_mask.npy\", mask_sam)\n",
    "\n",
    "# plot intersection images:\n",
    "masks_geometric = torch.cat(masks, dim=0)\n",
    "masks_sam = torch.from_numpy(mask_sam).unsqueeze(0)\n",
    "intersection = masks_intersection_batch(masks_geometric, masks_sam)\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "for im, ax, iou_score in zip(intersection, axs, iou):\n",
    "    ax.imshow(im)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(f\"IOU: {iou_score.item():.2f}\")\n",
    "    ax.title.set_size(30)\n",
    "plt.show()\n",
    "\n",
    "# use softmax to get pose distribution, with high low temperature:\n",
    "pose_distribution = torch.softmax(iou * 3, dim=0).numpy().squeeze()\n",
    "# plot pose distribution wide:\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.bar(range(len(pose_distribution)), pose_distribution)\n",
    "plt.xticks(range(len(pose_distribution)), [\"Pose 1\", \"Pose 2\", \"Pose 3\", \"Pose 4\"])\n",
    "plt.title(\"Pose distribution\", fontsize=30)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robo-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
