{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from camera_simulator import CameraSimulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageManipulator:\n",
    "    \"\"\"\n",
    "    Image manipulation functions that work both on batched data and single images.\n",
    "    Image batch dim is assumed to be [N, W, H, 3]\n",
    "    Single image dim is assumed to be [W, H, 3]\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_mask(images: np.ndarray, bg_value: int = 0, orig_dims: bool = False) -> np.ndarray:\n",
    "        mask = np.any(images != bg_value, axis=-1)\n",
    "        if orig_dims:\n",
    "            mask = np.broadcast_to(np.expand_dims(mask, axis=-1), images.shape)\n",
    "        return mask\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_bboxes(mask_batch: np.ndarray, margin_factor: float = 1.2) -> np.ndarray:\n",
    "        x = np.any(mask_batch, axis=-1)\n",
    "        y = np.any(mask_batch, axis=-2)\n",
    "\n",
    "        def argmin_argmax(arr: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "            # find smallest and largest indices\n",
    "            imin = np.argmax(arr, axis=-1)\n",
    "            arr = np.flip(arr, axis=-1)\n",
    "            length = arr.shape[-1]\n",
    "            imax = length - np.argmax(arr, axis=-1)\n",
    "\n",
    "            # add margin to the indices\n",
    "            diff = imax - imin\n",
    "            margin = (diff * (margin_factor - 1)).astype(imin.dtype)\n",
    "            imin = imin - margin\n",
    "            imax = imax + margin\n",
    "\n",
    "            # make sure we're within bounds\n",
    "            imin = np.maximum(imin, 0)\n",
    "            imax = np.minimum(imax, length - 1)\n",
    "            return imin, imax\n",
    "\n",
    "        xmin, xmax = argmin_argmax(x)\n",
    "        ymin, ymax = argmin_argmax(y)\n",
    "\n",
    "        return np.stack((xmin, ymin, xmax, ymax), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manipulated_object import ManipulatedObject\n",
    "\n",
    "\n",
    "class ImageSampler:\n",
    "    def __init__(\n",
    "        self,\n",
    "        world_file: str,\n",
    "        object_position: tuple[int, int, int],\n",
    "        camera_position: tuple[int, int, int],\n",
    "        camera_rotation: np.ndarray,\n",
    "        camera_resolution: tuple[int, int] = (300, 300),\n",
    "        camra_fov: int = 45,\n",
    "        render_depth: bool = False,\n",
    "        simulation_time: float = 0,\n",
    "    ):\n",
    "        self._camera = CameraSimulator(resolution=camera_resolution, fovy=camra_fov, world_file=world_file)\n",
    "        self._camera_position = camera_position\n",
    "        self._camera_rotation = camera_rotation\n",
    "        self._object_position = object_position\n",
    "        self._simulate_depth = render_depth\n",
    "        self._simulation_time = simulation_time\n",
    "\n",
    "    def _render(self):\n",
    "        if self._simulate_depth:\n",
    "            return self._camera.render_depth(self._camera_rotation, self._camera_position)\n",
    "        return self._camera.render(self._camera_rotation, self._camera_position)\n",
    "\n",
    "    def get_view(\n",
    "        self,\n",
    "        orient: tuple[float, float, float],\n",
    "    ) -> tuple[np.ndarray, tuple[float, float, float]]:\n",
    "\n",
    "        self._camera.set_object_position(self._object_position)\n",
    "        self._camera.set_object_orientation(orient)\n",
    "        self._camera.simulate_seconds(self._simulation_time)\n",
    "        image = self._render()\n",
    "        return image, self._camera.get_object_orientation()\n",
    "\n",
    "    def get_view_cropped(\n",
    "        self,\n",
    "        orient: tuple[float, float, float],\n",
    "        margin_factor: float = 1.2,\n",
    "    ) -> tuple[np.ndarray, tuple[float, float, float]]:\n",
    "\n",
    "        image, orient = self.get_view(orient)\n",
    "        mask = ImageManipulator.calc_mask(image, bg_value=0, orig_dims=False)\n",
    "        x1, y1, x2, y2 = ImageManipulator.calc_bboxes(mask, margin_factor)\n",
    "        cropped = image[x1:x2, y1:y2, :]\n",
    "        return cropped, orient\n",
    "\n",
    "    def get_view_batch(\n",
    "        self,\n",
    "        orient_list: list[tuple[float, float, float]],\n",
    "    ) -> tuple[np.ndarray, np.ndarray]:\n",
    "        \n",
    "        image_list = []\n",
    "        orient_list = []\n",
    "        for orient in orient_list:\n",
    "            image, orient = self.get_view(orient)\n",
    "            image_list.append(image)\n",
    "            orient_list.append(orient)\n",
    "        images = np.stack(image_list, axis=0)\n",
    "        orients = np.asanyarray(orient_list)\n",
    "        return images, orients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QStandardPaths: wrong permissions on runtime directory /run/user/1000/, 0755 instead of 0700\n"
     ]
    }
   ],
   "source": [
    "from camera_utils import xy_axes_to_rotation\n",
    "camera_rotation = xy_axes_to_rotation([1, 0, 0], [0, 0, 1])\n",
    "\n",
    "viewer = ImageSampler(\n",
    "    world_file=\"data/world_mug_sim.xml\",\n",
    "    object_position=(0, 1.3, 0.1),\n",
    "    camera_position=(0, 0, 0.1),           \n",
    "    camera_rotation=camera_rotation,\n",
    "    camra_fov=60,\n",
    ")\n",
    "\n",
    "random_orientations = np.random.uniform(0, 2 * np.pi, size=(100, 3))\n",
    "for orient in random_orientations:\n",
    "    im, _ = viewer.get_view(orient)\n",
    "    cv.imshow(\"img\", im)\n",
    "    cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camera_utils import xy_axes_to_rotation\n",
    "camera_rotation = xy_axes_to_rotation([1, 0, 0], [0, 0, 1])\n",
    "\n",
    "viewer = ImageSampler(\n",
    "    world_file=\"data/world_mug.xml\", \n",
    "    object_position=(0, 1.3, 0.3),\n",
    "    camera_position=(0, 0, 0.1),\n",
    "    camera_rotation=camera_rotation,\n",
    "    simulation_time=3,\n",
    "    camra_fov=60,\n",
    ")\n",
    "\n",
    "random_orientations = np.random.uniform(0, 2 * np.pi, size=(100, 3))\n",
    "for orient in random_orientations:\n",
    "    im, _ = viewer.get_view(orient)\n",
    "    cv.imshow(\"img\", im)\n",
    "    cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robo-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
