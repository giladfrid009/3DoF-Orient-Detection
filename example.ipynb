{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import torch\n",
    "from camera_simulator import CameraSimulator\n",
    "from camera_utils import xy_axes_to_frame_rotation, get_torch3d_R_T\n",
    "from matplotlib import pyplot as plt\n",
    "from sam_segmentation import SAMSegmentation\n",
    "from utils import (\n",
    "    plot_segmentation_mask,\n",
    "    plot_grid_segmentation_masks,\n",
    "    masks_intersection_batch,\n",
    "    compute_masks_IOU_batch,\n",
    ")\n",
    "from geometric_mesh_segmentation import CameraParameters, get_mesh_segmentation_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mesh = \"./data/meshes/mug.obj\"\n",
    "scale = 0.02\n",
    "\n",
    "cam_pos = [0.5, -0.5, 1.75]\n",
    "cam_xy_axes = [[0.685, 0.728, 0.000], [-0.487, 0.458, 0.743]]\n",
    "cam_frame_R = xy_axes_to_frame_rotation(cam_xy_axes[0], cam_xy_axes[1])\n",
    "cam_resx, cam_resy = 300, 300\n",
    "cam_fov = 45\n",
    "cam_znear, cam_zfar = 0.1, 100\n",
    "\n",
    "table_height = 1\n",
    "obj_position_actual = [0, 0, 0.08 + table_height]\n",
    "obj_orientation_actual = [2.1, 0, 1.57]\n",
    "obj_positions = [\n",
    "    [0, 0, 0.08 + table_height],\n",
    "    [0, 0, 0.08 + table_height],\n",
    "    [0, 0, 0.12 + table_height],\n",
    "    [0, 0, 0.12 + table_height],\n",
    "]\n",
    "\n",
    "# range is [0 - 2pi, -pi/2 - pi/2, 0 - 2pi]\n",
    "obj_orientations = [[2.1, 0, 1.57], [0, 0, 1.57], [0, -0.2, 0], [3.14, -0.2, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = np.zeros([cam_resy, cam_resx])\n",
    "\n",
    "cam_sim = CameraSimulator(resolution=(cam_resy, cam_resx), fovy=cam_fov, world_file=\"data/world_mug_sim.xml\")\n",
    "\n",
    "random_orientations = np.random.uniform(0, 2 * np.pi, size=(1000, 3))\n",
    "random_position = np.asanyarray(obj_position_actual) + np.random.uniform(-0.1, 0.1, size=(1000, 3))\n",
    "\n",
    "images_list = []\n",
    "for position, orient in zip(random_position, random_orientations):\n",
    "    cam_sim.set_manipulated_object_position(position.tolist())\n",
    "    cam_sim.set_manipulated_object_orientation_euler(orient)\n",
    "    im = cam_sim.render(cam_frame_R, cam_pos)\n",
    "    images_list.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mask(images: np.ndarray, bg_value: int = 0) -> np.ndarray:\n",
    "    mask = np.any(images != bg_value, axis=-1)\n",
    "    mask = np.broadcast_to(np.expand_dims(mask, axis=-1), images.shape)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_bboxes(image_batch: np.ndarray, bg_value: int = 0, margin_factor: float = 1.2) -> np.ndarray:\n",
    "    masks = np.any(image_batch != bg_value, axis=-1)\n",
    "    x = np.any(masks, axis=-1)\n",
    "    y = np.any(masks, axis=-2)\n",
    "\n",
    "    def argmin_argmax(arr: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "        # find smallest and largest indices\n",
    "        imin = np.argmax(arr, axis=-1)\n",
    "        arr = np.flip(arr, axis=-1)\n",
    "        length = arr.shape[-1]\n",
    "        imax = length - np.argmax(arr, axis=-1)\n",
    "\n",
    "        # add margin to the indices\n",
    "        diff = imax - imin\n",
    "        margin = (diff * (margin_factor - 1)).astype(imin.dtype)\n",
    "        imin = imin - margin\n",
    "        imax = imax + margin\n",
    "\n",
    "        # make sure we're within bounds\n",
    "        imin = np.maximum(imin, 0)\n",
    "        imax = np.minimum(imax, length - 1)\n",
    "        return imin, imax\n",
    "\n",
    "    xmin, xmax = argmin_argmax(x)\n",
    "    ymin, ymax = argmin_argmax(y)\n",
    "\n",
    "    return np.stack((xmin, ymin, xmax, ymax), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch = np.stack(axis=0, arrays=images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 300, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "masks = calc_mask(image_batch)\n",
    "#cv.imshow(\"img\", image_batch[0])\n",
    "#cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "print(masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = get_bboxes(image_batch, margin_factor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bboxes[214])\n",
    "\n",
    "for i, bbox in enumerate(bboxes[0]):\n",
    "    cv.imshow(\"img\", image_batch[i][bbox[0] : bbox[2], bbox[1] : bbox[3]])\n",
    "    cv.waitKey(0)\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch[1][masks[0]] = 100\n",
    "\n",
    "cv.imshow(\"img\", image_batch[1])\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sam to segment actual image and show it\n",
    "cam_sim.set_manipulated_object_position(obj_position_actual)\n",
    "cam_sim.set_manipulated_object_orientation_euler(obj_orientation_actual)\n",
    "im_actual = cam_sim.render(cam_frame_R, cam_pos)\n",
    "\n",
    "sam = SAMSegmentation()\n",
    "mask_sam, score = sam.segment_image_center(im_actual, best_out_of_3=True)\n",
    "plot_segmentation_mask(im_actual, mask_sam, mask_alpha=0.95, color=[30, 255, 30])\n",
    "iou = compute_masks_IOU_batch(torch.from_numpy(mask_sam).unsqueeze(0), torch.cat(masks))\n",
    "# save sam mask:\n",
    "np.save(\"./sam_mask.npy\", mask_sam)\n",
    "\n",
    "# plot intersection images:\n",
    "masks_geometric = torch.cat(masks, dim=0)\n",
    "masks_sam = torch.from_numpy(mask_sam).unsqueeze(0)\n",
    "intersection = masks_intersection_batch(masks_geometric, masks_sam)\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "for im, ax, iou_score in zip(intersection, axs, iou):\n",
    "    ax.imshow(im)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(f\"IOU: {iou_score.item():.2f}\")\n",
    "    ax.title.set_size(30)\n",
    "plt.show()\n",
    "\n",
    "# use softmax to get pose distribution, with high low temperature:\n",
    "pose_distribution = torch.softmax(iou * 3, dim=0).numpy().squeeze()\n",
    "# plot pose distribution wide:\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.bar(range(len(pose_distribution)), pose_distribution)\n",
    "plt.xticks(range(len(pose_distribution)), [\"Pose 1\", \"Pose 2\", \"Pose 3\", \"Pose 4\"])\n",
    "plt.title(\"Pose distribution\", fontsize=30)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robo-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
