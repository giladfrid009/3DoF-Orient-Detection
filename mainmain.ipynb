{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from view_sampler import ViewSampler, CameraConfig\n",
    "from manipulated_object import ObjectPosition\n",
    "import loss_funcs\n",
    "from evaluate import eval_funcs\n",
    "from algs import *\n",
    "\n",
    "from utils.orient import OrientUtils\n",
    "from evaluate.evaluator import Evaluator\n",
    "from utils.visualize import SearchPlotter\n",
    "from utils.image import ImageUtils\n",
    "\n",
    "import mealpy\n",
    "import cv2 as cv\n",
    "\n",
    "plotter = SearchPlotter(update_freq=100)\n",
    "\n",
    "# Create a camera configuration\n",
    "cam_config = CameraConfig(location=(0, 0, 0.1), rotation=(np.pi / 2, 0, 0), fov=60)\n",
    "world_viewer = ViewSampler(\"data/mug/world.xml\", cam_config, simulation_time=5)\n",
    "sim_viewer = ViewSampler(\"data/mug/world_sim.xml\", cam_config)\n",
    "\n",
    "loss_func = loss_funcs.IOU()\n",
    "\n",
    "alg = UniformSampling(sim_viewer, loss_func=loss_func)\n",
    "alg_config = UniformSampling.Config(time_limit=200, min_samples=350)\n",
    "\n",
    "eval_func=eval_funcs.XorDiff(0.1)\n",
    "evaluator = Evaluator(world_viewer, eval_func=eval_func)\n",
    "\n",
    "init_location = (0, 1.3, 0.3)\n",
    "random_orientations = OrientUtils.generate_random(80)\n",
    "eval_positions = [ObjectPosition(orient, init_location) for orient in random_orientations]\n",
    "\n",
    "for pos in eval_positions:\n",
    "    orig_img, new_pos = world_viewer.get_view_cropped(pos)\n",
    "    orient, loss = alg.solve(orig_img, new_pos.location, alg_config)\n",
    "    pred_img, _ = world_viewer.get_view_cropped(ObjectPosition(orient, new_pos.location))\n",
    "\n",
    "    cv.imshow(\"Original\", orig_img)\n",
    "    cv.waitKey(0)\n",
    "    cv.imshow(\"Predicted\", pred_img)\n",
    "    cv.waitKey(0)\n",
    "\n",
    "    orig_depth, _ = world_viewer.get_view_cropped(new_pos, depth=True, allow_simulation=False)\n",
    "    pred_depth, _ = world_viewer.get_view_cropped(ObjectPosition(orient, new_pos.location), depth=True, allow_simulation=False)\n",
    "\n",
    "    eval_loss = eval_func(orig_depth, pred_depth)\n",
    "    print(eval_loss)\n",
    "\n",
    "for alg, config in [(alg, alg_config)]:\n",
    "    eval_losses = evaluator.evaluate(alg, config, eval_positions)\n",
    "    print(f\"{type(alg).__name__}: {eval_losses}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from view_sampler import ViewSampler, CameraConfig\n",
    "from manipulated_object import ObjectPosition\n",
    "import loss_funcs\n",
    "from evaluate import eval_funcs\n",
    "from algs import *\n",
    "\n",
    "from utils.orient import OrientUtils\n",
    "from evaluate.evaluator import Evaluator\n",
    "# from utils.visualize import SearchPlotter\n",
    "from utils.image import ImageUtils\n",
    "\n",
    "import mealpy\n",
    "import cv2 as cv\n",
    "\n",
    "# plotter = SearchPlotter(update_freq=100, alpha=[0.985])\n",
    "\n",
    "# Create a camera configuration\n",
    "cam_config = CameraConfig(location=(0, 0, 0.3), rotation=(np.pi / 2, 0, 0), fov=60)\n",
    "world_viewer = ViewSampler(\"data/hammer/world.xml\", cam_config, simulation_time=5)\n",
    "sim_viewer = ViewSampler(\"data/hammer/world_sim.xml\", cam_config)\n",
    "\n",
    "loss_func = loss_funcs.IOU()\n",
    "alg_config = MealAlgorithm.Config(time_limit=15, silent=True)\n",
    "\n",
    "eval_func=eval_funcs.XorDiff(0.1)\n",
    "\n",
    "evaluator = Evaluator(world_viewer, eval_func=eval_func)\n",
    "# evaluator.register_callback(lambda x: plotter.reset())\n",
    "\n",
    "init_location = (0, 1.3, 0.3)\n",
    "random_orientations = OrientUtils.generate_uniform(3)\n",
    "eval_positions = [ObjectPosition(orient, init_location) for orient in random_orientations]\n",
    "\n",
    "algorithms: list[MealAlgorithm] = [\n",
    "    MealAlgorithm(sim_viewer, loss_func, mealpy.physics_based.SA.OriginalSA(temp_init=10 * 2 * np.pi, step_size=0.1)),\n",
    "    MealAlgorithm(sim_viewer, loss_func, mealpy.physics_based.SA.SwarmSA(temp_init=10 * 2 * np.pi, step_size=np.pi/100)),\n",
    "    MealAlgorithm(sim_viewer, loss_func, mealpy.swarm_based.PSO.OriginalPSO()),\n",
    "    MealAlgorithm(sim_viewer, loss_func, mealpy.swarm_based.PSO.AIW_PSO()),\n",
    "]\n",
    "# meal_alg = mealpy.human_based.BRO.DevBRO()\n",
    "# meal_alg = mealpy.math_based.CEM.OriginalCEM()\n",
    "# meal_alg = mealpy.music_based.HS.DevHS(pop_size=10)\n",
    "# meal_alg = mealpy.swarm_based.PSO.OriginalPSO()\n",
    "# meal_alg = mealpy.physics_based.SA.OriginalSA(pop_size=10, temp_init=10 * 2 * np.pi, step_size=0.2)\n",
    "# meal_alg = mealpy.human_based.ICA.OriginalICA(empire_count=7, revolution_rate=0.4) # best!!\n",
    "# meal_alg = mealpy.bio_based.BBO.DevBBO() # potentially good!\n",
    "meal_alg = mealpy.bio_based.TSA.OriginalTSA() # potentially good!\n",
    "\n",
    "algorithms: list[MealAlgorithm] = [\n",
    "    MealAlgorithm(sim_viewer, loss_func, meal_alg),\n",
    "]\n",
    "\n",
    "# evaluator.enable_logging(\"Ealuations/UniformDet/Mug/IOU/\")\n",
    "for alg in algorithms:\n",
    "    # alg.register_callback(plotter.add_data)\n",
    "    eval_losses = evaluator.evaluate(alg, alg_config, eval_positions)\n",
    "    print(f\"{alg.get_name()}: {eval_losses}\")\n",
    "\n",
    "world_viewer.close()\n",
    "sim_viewer.close()\n",
    "# plotter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loss_funcs\n",
    "from algs import *\n",
    "\n",
    "import mealpy\n",
    "from multiprocessing import Process\n",
    "import evaluation_process as ev\n",
    "\n",
    "loss_func = loss_funcs.IOU()\n",
    "alg_config = MealAlgorithm.Config(time_limit=15, silent=True)\n",
    "root_path = \"Ealuations/OverNight/UniformDet/Hammer/IOU/\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for idx, (alg_name, meal_alg) in enumerate(mealpy.get_all_optimizers().items()):\n",
    "        if \"DevSARO\" not in alg_name:\n",
    "            continue\n",
    "        print(f\"===================== Epoch {idx} =====================\")\n",
    "        print(f\"Starting Evaluation of: {alg_name}\")\n",
    "        p = Process(target=ev.evaluate, args=(meal_alg,alg_config,loss_func,root_path))\n",
    "        p.start()\n",
    "        p.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.orient import OrientUtils\n",
    "len(OrientUtils.generate_uniform(9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from evaluate.eval_log import EvalLog\n",
    "from mealpy.utils.history import History\n",
    "from utils.file import LogFiles\n",
    "import numpy as np\n",
    "\n",
    "path = \"AllOptimizers2/\"\n",
    "\n",
    "\n",
    "directories = LogFiles(path, scan_dirs=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/guycoh/RoboticsAndAI/Robotics-Proj/optimizers2.zip'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.make_archive(\"optimizers2\",'zip','AllOptimizers2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate experiment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/guycoh/RoboticsAndAI/Robotics-Proj/AllOptimizers/android\n",
      "/home/guycoh/RoboticsAndAI/Robotics-Proj/AllOptimizers/dino\n",
      "/home/guycoh/RoboticsAndAI/Robotics-Proj/AllOptimizers/hammer\n",
      "/home/guycoh/RoboticsAndAI/Robotics-Proj/AllOptimizers/mug\n",
      "/home/guycoh/RoboticsAndAI/Robotics-Proj/AllOptimizers/nescafe\n",
      "/home/guycoh/RoboticsAndAI/Robotics-Proj/AllOptimizers/screwdriver\n",
      "/home/guycoh/RoboticsAndAI/Robotics-Proj/AllOptimizers/shoe\n",
      "/home/guycoh/RoboticsAndAI/Robotics-Proj/AllOptimizers/sofa\n",
      "/home/guycoh/RoboticsAndAI/Robotics-Proj/AllOptimizers/stack_rings\n"
     ]
    }
   ],
   "source": [
    "# merge results\n",
    "path = \"AllOptimizers3/\"\n",
    "new_root = \"AllOptimizers/\"\n",
    "\n",
    "directories = LogFiles(path, scan_dirs=True)\n",
    "\n",
    "for directory in directories:\n",
    "    obj_name = directories.get_filename()\n",
    "    files = LogFiles(directory)\n",
    "    dst_folder = new_root + obj_name\n",
    "    print(dst_folder)\n",
    "    for file in files:\n",
    "        files.copy(dst_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WMQIMRFO not run for android\n",
      "DevVCS not run for android\n",
      "OriginalVCS not run for android\n",
      "WMQIMRFO not run for dino\n",
      "DevVCS not run for dino\n",
      "OriginalVCS not run for dino\n",
      "WMQIMRFO not run for hammer\n",
      "DevVCS not run for hammer\n",
      "OriginalVCS not run for hammer\n",
      "WMQIMRFO not run for mug\n",
      "DevVCS not run for mug\n",
      "OriginalVCS not run for mug\n",
      "WMQIMRFO not run for nescafe\n",
      "DevVCS not run for nescafe\n",
      "OriginalVCS not run for nescafe\n",
      "WMQIMRFO not run for screwdriver\n",
      "DevVCS not run for screwdriver\n",
      "OriginalVCS not run for screwdriver\n",
      "WMQIMRFO not run for shoe\n",
      "DevVCS not run for shoe\n",
      "OriginalVCS not run for shoe\n",
      "WMQIMRFO not run for sofa\n",
      "DevVCS not run for sofa\n",
      "OriginalVCS not run for sofa\n",
      "WMQIMRFO not run for stack_rings\n",
      "DevVCS not run for stack_rings\n",
      "OriginalVCS not run for stack_rings\n",
      "{'AllOptimizers/android': 212, 'AllOptimizers/dino': 212, 'AllOptimizers/hammer': 212, 'AllOptimizers/mug': 212, 'AllOptimizers/nescafe': 212, 'AllOptimizers/screwdriver': 212, 'AllOptimizers/shoe': 212, 'AllOptimizers/sofa': 212, 'AllOptimizers/stack_rings': 212}\n"
     ]
    }
   ],
   "source": [
    "# check if all optimizers were run\n",
    "import mealpy\n",
    "directories = LogFiles(new_root, scan_dirs=True)\n",
    "all_optimizers = [alg_name for alg_name in mealpy.get_all_optimizers().keys()]\n",
    "\n",
    "count = {}\n",
    "for directory in directories:\n",
    "    eval_files = LogFiles(directory, return_full_path=False)\n",
    "    object_dir = directories.get_filename()\n",
    "    count[directory] = len(eval_files)\n",
    "    \n",
    "    for optimizer in all_optimizers:\n",
    "        if optimizer not in eval_files:\n",
    "            print(f\"{optimizer} not run for {object_dir}\")\n",
    "        # if :\n",
    "        #     print(f\"{optimizer} not in {directory3}\")\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "\n",
    "# count = {}\n",
    "# for directory in directories:\n",
    "#     eval_files = LogFiles(directory, return_full_path=False)\n",
    "#     object_dir = directories.get_filename()\n",
    "#     directory3 = \"AllOptimizers3/\"+object_dir\n",
    "#     eval3_files = LogFiles(directory3, return_full_path=False)\n",
    "#     count[directory] = len(eval_files)\n",
    "#     count[directory3] = len(eval3_files)\n",
    "    \n",
    "#     eval_file_list = [f.split('_')[0] for f in eval_files]\n",
    "#     for filename3 in eval3_files:\n",
    "#         found = False\n",
    "\n",
    "#         algname3 = filename3.split('_')[0]\n",
    "#         # print(algname3)\n",
    "#         for filename in eval_files:\n",
    "#              algname = filename.split('_')[0]\n",
    "#              if algname == algname3:\n",
    "#                  found = True\n",
    "#                  print(f\"{algname} was found in both folders of {object_dir}!!!\")\n",
    "#                  break\n",
    "        # if not found:\n",
    "            # print(f\"{algname3} not found, is found at {eval3_files.get_path()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = []\n",
    "stat_data = []\n",
    "count = {}\n",
    "for directory in directories:\n",
    "    files = LogFiles(directory, return_full_path=False)\n",
    "    count[directory] = len(files)\n",
    "    for filename in files:\n",
    "        pass\n",
    "        df = files.to_dataframe(add_params=True)\n",
    "        df = df.assign(object=directories.get_filename())\n",
    "        raw_data.append(df)\n",
    "\n",
    "        stat_df = files.eval_stats_dataframe(False)\n",
    "        stat_df = stat_df.assign(object=directories.get_filename())\n",
    "        stat_data.append(stat_df)\n",
    "        \n",
    "\n",
    "\n",
    "dataframe = pd.concat(raw_data, axis=0, ignore_index=True)\n",
    "statsframe = pd.concat(stat_data, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statsframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# medians = pd.DataFrame(medians)\n",
    "statsframe.sort_values(by='median', inplace=True)\n",
    "statsframe.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size':5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10,40))\n",
    "g = sns.catplot(\n",
    "    data=dataframe,\n",
    "    x='alg',\n",
    "    y=\"eval_loss\",\n",
    "    row=\"object\",\n",
    "    hue=\"object\",\n",
    "    kind=\"box\",\n",
    "    errorbar=\"sd\",\n",
    "    aspect=6,\n",
    "    legend='brief',\n",
    "    # col_order=statsframe['alg'],\n",
    "    order=statsframe['alg'],\n",
    "    # hue_order=medians[category],\n",
    "    # col_wrap=20,\n",
    ")\n",
    "# g.figure.set_dpi(400)\n",
    "# g.ax.tick_params(axis=\"x\", rotation=90)\n",
    "# g.ax.set_title(f\"PSO GridSearch ordered by median eval loss\")\n",
    "\n",
    "# g.ax.autoscale_view()\n",
    "# g.ax.autoscale()\n",
    "g.figure.tight_layout()\n",
    "g.figure.savefig(\"AllOptimizers1.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detele?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx, file_path in enumerate(statsframe['path'].to_list()):\n",
    "    root = files.root\n",
    "    log = MealLog.load(file_path)\n",
    "    params = log.alg_params\n",
    "    if params['empire_count'] == 7 and params['revolution_prob'] == 0.4 and params['revolution_rate'] == 0.4:\n",
    "        print(f\"position={idx} - {log.alg_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import cv2 as cv\n",
    "\n",
    "from view_sampler import *\n",
    "from algs import *\n",
    "\n",
    "import loss_funcs\n",
    "from evaluate import eval_funcs\n",
    "\n",
    "from evaluate.dataset import Dataset\n",
    "from evaluate.eval_log import MealLog\n",
    "from evaluate.evaluator import Evaluator\n",
    "from evaluate.dataset import Dataset\n",
    "from utils.visualize import *\n",
    "from utils.concurrent import TqdmPool, silence_output\n",
    "\n",
    "from main2 import evaluate\n",
    "\n",
    "import mealpy\n",
    "\n",
    "\n",
    "OBJECT_NAMES = [\"airplane\", \"hammer\", \"mug\"]\n",
    "\n",
    "PARAMS: dict[str, dict[str, list]] = {\n",
    "    mealpy.swarm_based.PSO.OriginalPSO.__name__: {\n",
    "        \"c1\": [1, 2.05, 3],\n",
    "        \"c2\": [1, 2.05, 3],\n",
    "        \"w\": [0.2, 0.4, 0.8],\n",
    "    },\n",
    "\n",
    "    mealpy.human_based.ICA.OriginalICA.__name__: {\n",
    "        \"empire_count\": [4, 7, 10],\n",
    "        \"assimilation_coeff\": [1.5, 2.5],\n",
    "        \"revolution_prob\": np.linspace(0.02, 0.4, 3),\n",
    "        \"revolution_rate\": np.linspace(0.05, 0.4, 3),\n",
    "        \"revolution_step_size\": np.linspace(0.05, 0.3, 3),\n",
    "    },\n",
    "    mealpy.human_based.SARO.OriginalSARO.__name__: {\n",
    "        \"se\": [0.3, 0.5, 0.7],\n",
    "        \"mu\": [5, 10, 15, 20],\n",
    "    },\n",
    "\n",
    "    mealpy.evolutionary_based.DE.OriginalDE.__name__: {\"strategy\": range(6)},\n",
    "    mealpy.math_based.PSS.OriginalPSS.__name__: {\n",
    "        \"acceptance_rate\": [0.8, 0.9, 0.95],\n",
    "    },\n",
    "    mealpy.math_based.HC.OriginalHC.__name__: {\"neighbour_size\": [50, 200, 700, 950]},\n",
    "}\n",
    "\n",
    "\n",
    "OPTIMIZERS = [\n",
    "    mealpy.swarm_based.PSO.OriginalPSO,\n",
    "    mealpy.swarm_based.MSA.OriginalMSA,\n",
    "    mealpy.swarm_based.SCSO.OriginalSCSO,\n",
    "    mealpy.physics_based.SA.OriginalSA,\n",
    "    mealpy.physics_based.EVO.OriginalEVO,\n",
    "    mealpy.physics_based.EFO.DevEFO,\n",
    "    mealpy.physics_based.EO.ModifiedEO,\n",
    "    mealpy.human_based.ICA.OriginalICA,\n",
    "    mealpy.human_based.FBIO.DevFBIO,\n",
    "    mealpy.human_based.SARO.OriginalSARO,\n",
    "    mealpy.evolutionary_based.GA.BaseGA,\n",
    "    mealpy.evolutionary_based.CRO.OCRO,\n",
    "    mealpy.evolutionary_based.DE.OriginalDE,\n",
    "    mealpy.math_based.PSS.OriginalPSS,\n",
    "    mealpy.math_based.SCA.DevSCA,\n",
    "    mealpy.math_based.HC.OriginalHC,\n",
    "]\n",
    "\n",
    "\n",
    "OBJ_LOCATION = (0, 1.3, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exec = TqdmPool(4)\n",
    "\n",
    "run_config = MealRunConfig(time_limit=15, silent=True, seed=0)\n",
    "\n",
    "dataset = Dataset.create_random(location=OBJ_LOCATION, num_samples=20, seed=1)\n",
    "\n",
    "results = []\n",
    "\n",
    "tasks = []\n",
    "\n",
    "for optimizer_type in OPTIMIZERS:\n",
    "\n",
    "    optimizer_params = PARAMS[optimizer_type.__name__]\n",
    "\n",
    "    for param_config in product(*optimizer_params.values()):\n",
    "        if len(param_config) == 0:\n",
    "            continue\n",
    "\n",
    "        kwargs = {}\n",
    "        for i, param_name in enumerate(optimizer_params.keys()):\n",
    "            kwargs[param_name] = param_config[i]\n",
    "\n",
    "        try:\n",
    "            optimizer = optimizer_type()\n",
    "            optimizer.set_parameters(kwargs)\n",
    "\n",
    "            for obj_name in OBJECT_NAMES:\n",
    "\n",
    "                task = exec.submit(\n",
    "                    evaluate,\n",
    "                    optimizer=optimizer,\n",
    "                    run_config=run_config,\n",
    "                    obj_name=obj_name,\n",
    "                    eval_positions=dataset,\n",
    "                    log_folder=f\"grid_search/{obj_name}\",\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to create optimizer {optimizer_type.__name__} with params {kwargs}\")\n",
    "            print(str(e))\n",
    "\n",
    "exec.shutdown(wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec.shutdown(wait=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
