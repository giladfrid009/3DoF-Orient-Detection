{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ObjectPosition(orientation=array([ 3.09775176,  0.62042851, -1.76302832]), location=(0, 1.3, 0.3)), ObjectPosition(orientation=array([ 1.96867007, -0.52008766, -1.39901397]), location=(0, 1.3, 0.3)), ObjectPosition(orientation=array([ 0.14524103, -0.09522485, -1.27048798]), location=(0, 1.3, 0.3)), ObjectPosition(orientation=array([0.17771029, 0.19131372, 2.20805926]), location=(0, 1.3, 0.3)), ObjectPosition(orientation=array([-0.14091264, -0.25063472,  0.14480161]), location=(0, 1.3, 0.3)), ObjectPosition(orientation=array([-0.23880271, -0.37773243,  0.2445214 ]), location=(0, 1.3, 0.3)), ObjectPosition(orientation=array([-0.5238142 ,  0.13629684, -0.24455096]), location=(0, 1.3, 0.3)), ObjectPosition(orientation=array([-0.63795994,  0.14737725, -0.30336333]), location=(0, 1.3, 0.3))]\n",
      "Evaluating Algorithm: UniformSampling\n",
      "Alg Config: UniformSampling.Config(time_limit=200, rnd_seed=None, min_samples=10000, randomized=False)\n",
      "Loss Function: StructuralSimilarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1627b4d9b1451ab0f5c9b46531a07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22eba409498f4e2abed9d963bf89c9e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10648 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(eval_positions)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m alg, config \u001b[38;5;129;01min\u001b[39;00m [(alg, alg_config)]:\n\u001b[0;32m---> 38\u001b[0m     eval_losses \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43malg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_positions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(alg)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_losses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m plotter\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/source/Robotics-Proj/evaluate/evaluator.py:56\u001b[0m, in \u001b[0;36mEvaluator.evaluate\u001b[0;34m(self, alg, alg_config, eval_positions)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m position \u001b[38;5;129;01min\u001b[39;00m tqdm(eval_positions, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating: \u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     50\u001b[0m     ref_img, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld_viewer\u001b[38;5;241m.\u001b[39mget_view_cropped(\n\u001b[1;32m     51\u001b[0m         position,\n\u001b[1;32m     52\u001b[0m         depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     53\u001b[0m         allow_simulation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     54\u001b[0m     )\n\u001b[0;32m---> 56\u001b[0m     pred_orient, _ \u001b[38;5;241m=\u001b[39m \u001b[43malg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malg_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     ref_depth, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld_viewer\u001b[38;5;241m.\u001b[39mget_view_cropped(\n\u001b[1;32m     59\u001b[0m         position\u001b[38;5;241m=\u001b[39mposition,\n\u001b[1;32m     60\u001b[0m         depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     61\u001b[0m         allow_simulation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     64\u001b[0m     pred_depth, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld_viewer\u001b[38;5;241m.\u001b[39mget_view_cropped(\n\u001b[1;32m     65\u001b[0m         position\u001b[38;5;241m=\u001b[39mObjectPosition(pred_orient, position\u001b[38;5;241m.\u001b[39mlocation),\n\u001b[1;32m     66\u001b[0m         depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     67\u001b[0m         allow_simulation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     68\u001b[0m     )\n",
      "File \u001b[0;32m~/source/Robotics-Proj/algs/uniform_sampling.py:47\u001b[0m, in \u001b[0;36mUniformSampling.solve\u001b[0;34m(self, ref_img, ref_location, alg_config)\u001b[0m\n\u001b[1;32m     44\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_orient \u001b[38;5;129;01min\u001b[39;00m tqdm_bar:\n\u001b[0;32m---> 47\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_orient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;241m<\u001b[39m lowest_loss:\n\u001b[1;32m     50\u001b[0m         lowest_loss \u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[0;32m~/source/Robotics-Proj/algs/algorithm.py:41\u001b[0m, in \u001b[0;36mAlgorithm.calc_loss\u001b[0;34m(self, ref_location, ref_img, test_orient)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_loss\u001b[39m(\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     37\u001b[0m     ref_location: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m],\n\u001b[1;32m     38\u001b[0m     ref_img: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[1;32m     39\u001b[0m     test_orient: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m],\n\u001b[1;32m     40\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m---> 41\u001b[0m     test_img, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_test_viewer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_view_cropped\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mObjectPosition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_orient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_location\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_simulation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     pad_shape \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(ref_img\u001b[38;5;241m.\u001b[39mshape, test_img\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     47\u001b[0m     ref_img \u001b[38;5;241m=\u001b[39m ImageUtils\u001b[38;5;241m.\u001b[39mpad_to_shape(ref_img, pad_shape)\n",
      "File \u001b[0;32m~/source/Robotics-Proj/view_sampler.py:81\u001b[0m, in \u001b[0;36mViewSampler.get_view_cropped\u001b[0;34m(self, position, depth, margin_factor, allow_simulation)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_view_cropped\u001b[39m(\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     75\u001b[0m     position: ObjectPosition,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m     allow_simulation: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     79\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray, ObjectPosition]:\n\u001b[0;32m---> 81\u001b[0m     image, position \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_view\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_simulation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_simulation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     mask \u001b[38;5;241m=\u001b[39m ImageUtils\u001b[38;5;241m.\u001b[39mcalc_mask(image, bg_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     83\u001b[0m     x1, y1, x2, y2 \u001b[38;5;241m=\u001b[39m ImageUtils\u001b[38;5;241m.\u001b[39mcalc_bboxes(mask, margin_factor)\n",
      "File \u001b[0;32m~/source/Robotics-Proj/view_sampler.py:63\u001b[0m, in \u001b[0;36mViewSampler.get_view\u001b[0;34m(self, position, depth, allow_simulation)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimulator\u001b[38;5;241m.\u001b[39mset_object_orientation(position\u001b[38;5;241m.\u001b[39morientation)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimulator\u001b[38;5;241m.\u001b[39msimulate_seconds(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulation_time \u001b[38;5;28;01mif\u001b[39;00m allow_simulation \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 63\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m depth:\n\u001b[1;32m     66\u001b[0m     mask \u001b[38;5;241m=\u001b[39m ImageUtils\u001b[38;5;241m.\u001b[39mcalc_mask(image, bg_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/source/Robotics-Proj/view_sampler.py:51\u001b[0m, in \u001b[0;36mViewSampler._render_image\u001b[0;34m(self, depth)\u001b[0m\n\u001b[1;32m     49\u001b[0m     image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(image, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcamera_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcamera_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/source/Robotics-Proj/simulator.py:46\u001b[0m, in \u001b[0;36mSimulator.render\u001b[0;34m(self, cam_rot, cam_pos)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcam_xmat \u001b[38;5;241m=\u001b[39m Rotation\u001b[38;5;241m.\u001b[39mfrom_euler(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxyz\u001b[39m\u001b[38;5;124m\"\u001b[39m, cam_rot)\u001b[38;5;241m.\u001b[39mas_matrix()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_renderer\u001b[38;5;241m.\u001b[39mupdate_scene(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, camera\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_renderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "File \u001b[0;32m~/miniforge3/envs/robo-proj/lib/python3.11/site-packages/mujoco/renderer.py:239\u001b[0m, in \u001b[0;36mRenderer.render\u001b[0;34m(self, out)\u001b[0m\n\u001b[1;32m    237\u001b[0m   np\u001b[38;5;241m.\u001b[39mcopyto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scene\u001b[38;5;241m.\u001b[39mflags, original_flags)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m   \u001b[43m_render\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmjr_readPixels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mjr_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m out[:] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mflipud(out)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from view_sampler import ViewSampler, CameraConfig\n",
    "from manipulated_object import ObjectPosition\n",
    "import loss_funcs\n",
    "from evaluate import eval_funcs\n",
    "from algs import *\n",
    "\n",
    "from utils.orient import OrientUtils\n",
    "from evaluate.evaluator import Evaluator\n",
    "from utils.visualize import SearchPlotter\n",
    "\n",
    "import mealpy\n",
    "\n",
    "plotter = SearchPlotter(update_freq=100)\n",
    "\n",
    "# Create a camera configuration\n",
    "cam_config = CameraConfig(location=(0, 0, 0.1), rotation=(np.pi / 2, 0, 0), fov=60)\n",
    "world_viewer = ViewSampler(\"data/world_mug.xml\", cam_config, simulation_time=5)\n",
    "sim_viewer = ViewSampler(\"data/world_mug_sim.xml\", cam_config)\n",
    "\n",
    "loss_func = loss_funcs.StructuralSimilarity()\n",
    "\n",
    "alg = UniformSampling(sim_viewer, loss_func=loss_func)\n",
    "alg_config = UniformSampling.Config(time_limit=200, min_samples=10000)\n",
    "alg.register_callback(plotter.add_data)\n",
    "\n",
    "evaluator = Evaluator(world_viewer, eval_func=eval_funcs.NormXorDiff(obj_depth=1.0, method=\"mae\"))\n",
    "#evaluator.enable_logging(\"logs\")\n",
    "evaluator.register_callback(lambda x: plotter.reset())\n",
    "\n",
    "init_location = (0, 1.3, 0.3)\n",
    "random_orientations = OrientUtils.generate_random(8)\n",
    "eval_positions = [ObjectPosition(orient, init_location) for orient in random_orientations]\n",
    "\n",
    "print(eval_positions)\n",
    "\n",
    "for alg, config in [(alg, alg_config)]:\n",
    "    eval_losses = evaluator.evaluate(alg, config, eval_positions)\n",
    "    print(f\"{type(alg).__name__}: {eval_losses}\")\n",
    "\n",
    "plotter.close()\n",
    "world_viewer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robo-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
